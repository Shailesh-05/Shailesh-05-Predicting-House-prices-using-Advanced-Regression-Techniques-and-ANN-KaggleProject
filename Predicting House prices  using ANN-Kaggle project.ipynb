{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal     208500  \n",
       "1         5   2007        WD         Normal     181500  \n",
       "2         9   2008        WD         Normal     223500  \n",
       "3         2   2006        WD        Abnorml     140000  \n",
       "4        12   2008        WD         Normal     250000  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007        WD         Normal     175000  \n",
       "1456      2   2010        WD         Normal     210000  \n",
       "1457      5   2010        WD         Normal     266500  \n",
       "1458      4   2010        WD         Normal     142125  \n",
       "1459      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('train (3).csv')\n",
    "test_df=pd.read_csv('test (2).csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 0\n",
       "MSSubClass         0\n",
       "MSZoning           0\n",
       "LotFrontage      259\n",
       "LotArea            0\n",
       "                ... \n",
       "MoSold             0\n",
       "YrSold             0\n",
       "SaleType           0\n",
       "SaleCondition      0\n",
       "SalePrice          0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 0\n",
       "MSSubClass         0\n",
       "MSZoning           4\n",
       "LotFrontage      227\n",
       "LotArea            0\n",
       "                ... \n",
       "MiscVal            0\n",
       "MoSold             0\n",
       "YrSold             0\n",
       "SaleType           1\n",
       "SaleCondition      0\n",
       "Length: 80, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e76eefd588>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['MSZoning'].value_counts()\n",
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill Missing Values\n",
    "\n",
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())\n",
    "test_df['LotFrontage']=test_df['LotFrontage'].fillna(test_df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['MSZoning']=test_df['MSZoning'].fillna(test_df['MSZoning'].mode()[0])\n",
    "df.drop(['Alley'],axis=1,inplace=True)\n",
    "test_df.drop(['Alley'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])\n",
    "test_df['BsmtCond']=test_df['BsmtCond'].fillna(test_df['BsmtCond'].mode()[0])\n",
    "test_df['BsmtQual']=test_df['BsmtQual'].fillna(test_df['BsmtQual'].mode()[0])\n",
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])\n",
    "test_df['FireplaceQu']=test_df['FireplaceQu'].fillna(test_df['FireplaceQu'].mode()[0])\n",
    "test_df['GarageType']=test_df['GarageType'].fillna(test_df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PoolQC','Fence','MiscFeature','GarageYrBlt'],axis=1,inplace=True)\n",
    "test_df.drop(['PoolQC','Fence','MiscFeature','GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])\n",
    "\n",
    "test_df['GarageFinish']=test_df['GarageFinish'].fillna(test_df['GarageFinish'].mode()[0])\n",
    "test_df['GarageQual']=test_df['GarageQual'].fillna(test_df['GarageQual'].mode()[0])\n",
    "test_df['GarageCond']=test_df['GarageCond'].fillna(test_df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 75)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "Street           0\n",
       "                ..\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 75, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Id'],axis=1,inplace=True)\n",
    "test_df.drop(['Id'],axis=1,inplace=True)\n",
    "df.isnull().sum()\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])\n",
    "test_df['MasVnrType']=test_df['MasVnrType'].fillna(test_df['MasVnrType'].mode()[0])\n",
    "test_df['MasVnrArea']=test_df['MasVnrArea'].fillna(test_df['MasVnrArea'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e771a36748>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='coolwarm'')\n",
    "sns.heatmap(test_df.isnull(),yticklabels=False,cbar=False,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])\n",
    "test_df['BsmtExposure']=test_df['BsmtExposure'].fillna(test_df['BsmtExposure'].mode()[0])\n",
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])\n",
    "test_df['BsmtFinType2']=test_df['BsmtFinType2'].fillna(test_df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e7728e0ac8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAAE7CAYAAAB60ILNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2debxuY/n/39c5J5ySKUQ4HZlLlChUioZv/ZKkUJKheRLfBn0bDRUl3xJKk4iiSEmDWSozx0ySKL4NmhRJhOv3x3Wvs9d+9hrutfbeZ51z+rxfr+e1n7X2utd9P+tZz7Xu+xrN3RFCCLFgmTH0AIQQ4j8RCV8hhBgACV8hhBgACV8hhBgACV8hhBiAWfmH3iy3CCGE6My6VrVXM18hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBiAWUMPQCyezJ6z34R9991+wAAjEWLhxNw989Cbcw8UQggxn3Wtaq/UDkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQASvkIIMQCzhh6AWDyZPWe/Cfvuu/2AAUYixMKJuXvmoTfnHiiEEGI+61rVXqkdhBBiACR8hRBiACR8hRBiACR8hRBiACR8hRBiACR8hRBiACR8hRBiACR8hRBiACR8hRBiACR8hRBiACR8hRBiACR8hRBiACR8hRBiACR8hRBiACR8hRBiACR8hRBiAFTJQkwLo5Us/pOqWFRV8RjlP+l6iGpUyUIIIaYVVbIQQoiFBglfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYAAlfIYQYgFlDD0Asnsyes9+47ftuP2CgkQixcGLunnnozbkHCiGEmM+6VrVXagchhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgAhReLaUHhxUI0o/BiIYSYVqrDizXzFdNGefarma8Q49HMVwghphUl1hFCiIUGCV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgACV8hhBgCd+/0At7UtU3fdotrX4vCGHU9/jP6WhTGuNj21aOTK3oOrnO7xbWvRWGMuh7/GX0tCmNcXPuS2kEIIQZAwlcIIQagj/D9Us+++rRbXPvq225x7atvO/U1XDv1Ncl2lvQVQgghFiBSOwghxABI+AohxABI+AohxABI+E4zZrZM0yuj/d45+xZnzOz00vt9O7adYWZbTv2ohAjMbMle7XIMbmb2TOBqd7/XzHYFNgE+6+6/aWm3EvA+4InAUsV+d9+m5vgZwLXuvmH+RxjX/vHAOu5+jpnNBma5+z19zjVVmNkdgAMGPA64J71fGvitu89paX+lu28ysu8qd39qS7tO177UbjXg8cCsUpufNrVJ7TpdezN7FLDi6D1kZk9y9xtG9s3/vFXXI2NsF7v7Fh2O39zdL+nSx0j7ZwL7M3YdDXB3f0JDmyWBVwBzGX/tD6w5/jrivprwr9TXRi1jXAv4P3e/38yeC2wEHOfuf2tpl3V/9B2fmR3r7nuk97u7+9eaxjPJMTbeR+5+ZUs/TweOBpZ19zlmtjHwBnffK2ecs9oPAeAoYON08n1Th8cBz2lp9w3gW8BLgLcAuwN/qjvY3R82s2vMbI673545NgDM7I3Am4AVgLWA1YEvAM+rOPbJwJeB1YDTgfe5+13pf5e5+9Nr+riH5htqwkzW3ddIbT8PnOHup6XtlwJbNXyeVwO7AGua2Wmlfy0D/KWuXYlO1z71+UlgZ+BG4KHiIwCNwrfLtU/HvwI4EviLmTmwe+lGP554uJeZrEvOWanP73iee8/nizF0FdyJo4H/BuYxdh3b+B7w99Tm/ozjt+04plFOATY1s7WJ8Z4GnAD8v7oGHe+PvuPbuPR+b6CT8O04xv9tOJUDjRMV4HDic54K4O7XmNnW2YPNDJ27Mv39CPD68r6WdvPS32tL+37S0uY8YnZ4LnFDnAacltHX1cASwFWlfdfVHHsB8CJgOeA9wA3AWul/V7X11edFRfhh1b7S/x4PPBe4mHjIFa9NiFnldFz7XwBL9vhs2de+dPxq6f2Wqd/t6q4/8DfgO8B3S+/nvzLGdw/wMPAAcHfavrvh+Kuq3ne4Hpf2aHP9dNx3Df0Vv+n3AnvlfNa+90efcY2+79B+2sdY6uuyivvlmtz2uTPfe8zs/cCuwFZmNhN4REa7f6e/vzezlwC/I2ZFTRyQOaZR7nf3B8wMADObRf2MaWl3PyO9P9TM5gFnmNlrG9pMwMxWZvySvmm2/lcz+x/g66mPXYG76g72WI7/xsyeD9znsSpYF1gfuC5jeH2u/a3E95oz8yrT5doDzHD33wK4+0Vmtg3wAzNbo6bdK0rvj+w4Ntz90R2bzDCz5QmbSPHeSuf7a1Wj0jL2x2b2KeLhcH+pXdMy9iIze7K753y35T43B44ANiAegDOBe71iFTbCv9PqanfgpWlf22+68/3RY3yrm9nhxPUu3s/H3d851WNM49yQiSq641qa3ZFUD55k4l7Azbl95grfnYkl8Ovd/Q9mNgf4VEa7j5nZssC7iS9gGWI5Vou7/yRzTKP8xMw+AMw2sxcAbwO+X3Osmdmy7v731OeP07L0FGLp3IiZbUcsWR4H/JGYpf4ceFJDs12IB0thPPop8OrWTxXHPTsJgHOBK4jv4zUt7Tpfe+CfwNVmdi7jhUbbDd/l2gPca2Zruvtt6fy/TXrH7xE/gHG4+7nl7STcNwB+5+61KhgzW9/db6rT7TUIw2WJ5X8hcMvHOVCnux1dxm460m7CMrakG50F7GlmtxLXPkt3SzyMXgWcnPrbDVi7pQ3AnoQ66uPufpuZrUlMDCZgZkekMfa5P7qO772l91dkfI5Jj9HM9iNWmU8EfgS8mFgdtwnftxKqhzmEHDg77csbc5oqNx8UxpF/uftDpdnX6e7+75amnRnRqy5BPMVan+TJWPd64IXEjXsm8BWv+IBmtgtwq48YVdJD5cPu/saWvq4hfkjnuPtTk57n1e7+ppzP2IXCwGRmewGz3f2QHINbz752r9rvLUaPLtc+Hb8JcI+7/3Jk/xLEdfzayP7PAZ939xssPEQuImZQywF7u/tJNf18yd3fZGY/rv5YzcbHvpjZE9z91rZ9af/jm87l7UbtK9x9UzO7thDUZnaRu7d6eCTD6Bx3/0XLcZX3RWmMtffHZMZXOsfywN/q7qcpGON1hK75Knff2MweS9y/L61rMyVk6jbmAY8kDFR3ELq3b2S0W5eYrV2ftjcCPtRRr7I9cFDmsUukPp4MLNGln45juiL9vYZYQkPS/1Qc+11GdJR001deBWwBXAI8Ke2r1adO9tqna7hhej0i4/iZwNcncS1XB7ZO75cEHlVxzA2l93uTbADEyqOzXjC1rf1sxEpm2dL21sBniZVD631VNSaSDr6hzfE5+yqO+Wn6zo4DDkljbNU7EqqGXwC3pe2nkGFbKbVfHthoqsdH2JXWL90P5wF/JWaWz8/o71HAzJH785EtbQrd7TxihWjle66h3dz0+/5Dep0CzM29hrl+vubu/wR2AI5w95fTvMQu+DLwfpL+0d2vJZYg2bj7qbRbHUl6zV8Ry4AjgVvM7MUtbdY1sy+b2Vlmdl7xyhjW38xsaeLG+oaZfRZ4sObYI4HPAf9HGH2OT68HiZu/jb2Ja/hdj5nfE4Cqmdwona99Wvr/Mo3388DNZlbrkZHO+xCwUpq1dsLMXkcYVL+Sdj2eUD2M8kDp/QuIBxfu/jtKutiM/szMtjGzrxDfRx0nET9izOwpxJL5dkJAfb7h/Osn9dWyZrZD6bUHJV1iDeN+T0mH+LS2zwS8lhAw7wDuBdZgvI68jv2BpxMGTNz9amDNpgZmdr6Ff/oKxMTjGDP79BSPb2fGfhe7E9/vSoSx+aCWviAmHLNL27OBc1raXGFmyxG/mXmEmumyjL5OJO7fOen1/bQvj8ynXN/Z1+VF+9K+q1va7FB6vRL4BHBxRl83AWuXttcCbmppcw2ho3k6caM/DXha7tOV0NPtDrwTeEzbDGBk20b3TeWr57WfB6xX2l6XlhlbOu6LwOXAh4F3Fa+MdlleEsD5hHfKRoSwWDXtn9n2HafjnkHMXG8H/pG+s+Ubji97iBwKHJLezyj/r6Ldy4BjCFfAY0qvw4Eta9q8n/C+eJDwxCi8Mf4CHDyN98elFfdH7WcrHwu8ATggp02PcZXHcwrw5tJ2jofVhHu87b4fOXYuGTP68jVs21f3yjW49Z19/dnCmTukjdkrgd+3tCnrWR4Efk3c1G380d1vKW3fSixVmnjQ3Y/KOPc43P3e0mauH+LKZjbX3X+dtucQT/TOFLrMlsP6XPtHeEn/5+43m1mOV8vv0msG0MWz4F8+3ktiZs1xbyFWEKsA73b34nM8Hzijpg1m9nFgJ0LonggcSKiM2r6z8mx6G+Lex8PjpLaRu38P+J6ZbeHuF7f0UbQ5GDjYzA529/fntBk3ULPbqPAQ8YaAjsT1yfYx08zWISYQF7W0mWVmqxLX9IPTNL77k+fBnYS65z2l/z0yo8t7zWwTT8ZUM3sacF/N2G4k/OG/6e6/SuP6dUYfBeeZ2XuAbxKfcWfg+8kugbvf3dR4WlNKJiH9JcKX8y7gNuA13mJE6NnXUcSy9STiQuxILF8uBHD371S02Z8Q0N9lvGW00pWo1K6zUTCpRb7A2JJqHeCt7v6jmuPrvC6M0Jk1uo31ufZm9lXicx2fdr2G8Cnes6mvvpjZ/xI/sj0JD4m3A7+sE0JVQs0aotHM7E/E9T4M+IG7/8vMbm0TTEmNtCqhx3spsK67/zsJnu+7+6Yt7ZciDJBPYrzr0uta2i1P3BflNm0BLo8pbS5F3PcruPtHWto9khCgL0y7zgQ+5u7/amizI7G6ucDd35busU+5e60aoev4zOwZxIRmJeAwd/9o2v//gNe6e6OHkJltSgQX/S7tWhXY2d3nVRy7MaGK2wn4M/GAPslDndWKRfRqHe5t0as5wtciVHVfJt5MtbrYZAF/pbuflLwlZnhGqK+ZrU64Rj2TEAQXEBbtJh0dZnZMw7+96sZPT+WqY9tmDaPn2R54urt/oOW42Yy5Ut0IPOChM6069iHgN4yfhXnaXs3da3Wsk7j2SxIC8Fmpn58SXgaNPpPJm6BqdtMWyjyTiIwre0l80d0frjm+KtR6nrtX6kbT+V9IuPRtQ6zWng+s4e51Onosprc7EzPtkz35JJvZU4GV3f3Mls91MqEG24WYbb8G+Lm71+bkMLM3ECvM1Ql1zOaEuq2zR4aZXeDuz+rabkGRMz4zW2r0QWBmKzRNjNJ9vzmhAluPuKdu8gyvLAt/5J0JffQtwInu/uXWDzMZMnUbZxFP8p8Tiu+vAp/MaNdZp0n4yu1J6FNnAXsAZ3c9z4J+AZd0OHYrYhb8h4Zjfkm4AVX9747puPaT+OxPK72eCXyapCfNaPsI4oG0ATWRe4ROfm/C0+adpdeHyNQ5EpOGVxJ6xDuBE1qOn0m4Eva5HoVu9NrSZzyvpc11aYxXp+31gW9l9LVJ6bUpoaLJ8XY4G1iutL08cGbNsfumv0cQ+utxr2ka3w/L9wMxg82xP7Tah1raP5ewcd2fcewlxOTh0X36ytX5PsbdjzazvT2CIH5iZjnBEGcnnci3CEsn0LqsX8ndy7PYY81sn7aO+syYkz7zrYzlWDifmHk1PinNbIfS5gzipmpcQiTd0y7Ek3UlxoRHHYcRP4iqqLlDmvpKZF97MzvJ3XeymmQo3uLo7xOXdBfm3B9m9iJCNXI7YxFNb3T3s0YOfRSwIvEwLuvJ7yGWsa14zKK+DXzbzB5NGHSbjn/IzP5ppWCcDhT3z9+S/vIPhCGniX95qEUwsyU9gkPWy+irHNhR2Eh2ymi3opeS6Lj7XRYRm1X8PP3NDnqYgvGdSnxXryA8JE5jvP63jq55PDCzzYjV0SvS+L5EeLi0sQcxUbzGzC4CjvGRgKDGfnPGZ2aXuPvmZnYm8bT7HfBtd1+rpV3nZb2ZnQMcy5jLxquBPd29MklLqd3ZRGKQQl+5K6HjfEFDm68Qs5LCAPNa4CF3f0NLX+WHQ3FDfdndJxj4zOwAYjlzZ/pMpxB+hY1uPantDGBzd28zhFS1zb72Zraqu//eahz+vd3Rv6yfnkHMgA9390bhYWY3ETkdbk7b6wLfc/cNao6vDFRoOP+7mv7v7o1uUmZ2ErGMPZvxD7DGiL+kQjiF8M44hshg92F3/2JDm+8SP+R9CBXJXYQBtDbRzWSwCKl/uaeQ+PTdf9c7ZoybTszs7YSXy1zC66H1d5DsMY8ikurcB/VJr8zsIOK3eRdhNPtm02Stoc+ZwHaEUfgBQjNwhLdliMsUvtsCPyOeQEWo6gGeMnR1HOgS7v5Aw//nEB9iC2IWdhHwTm/JcmZmV7v7U9r2jfz/GnffuG3fZDCzvxCJez4N/MjDut9q9Cm175NVq+5cbdf+k+7+vrZ9Fe0Ki7YRD6PbgAPd/YKWdj91963a9pX+twnwP0xMu1gpMCzCRmtx98Y8ItYz4m+ymNlziBDnM1q+r6cS4eOFHeEKQt1zi5nN8ma9drHqKFYoWwFv8gZ9dno4voeJ178uRWzn8Y08MI2YEF1HqAJaH5hdSPfHicXDv+c5nkg8NF9KBIR8g7CZ7Nz6IJuMfqSDHsWIp/lXgDtbjn1mzr6KY84hZrsz02tX4NyWNleSspml7SfQ4ktIuL1dSETd/JXQhz8r/W/ZiuMfkb6YEwjH/mMIl68ZmdfuAGI5ZAvg2ldFZk2pH+fIuT9PLCd3JYxSpxJ+tduRspyNHH8ToS5Yh/DjXqv8/S0ML8ImslF6vxMxkdiHzExbhDvVpoT6rem4wjD0OmKGvXF6fzUxcWm899M5ViRSIr6UUEO0HZ/tF993fMB+Ta/Ma7hduo8OBbbNOP7tTNR/vy2j3aWEqnI3IvS//L/WaMHGma+NJauoxNuXX88g9JwvJxLWvD0NqjabV41FuzWBds2MeW9vdq16HiEMbyWE1OMJFUelD7OZvY24gfZlTP+1KfAxwon/A94wa07uPdsRqpRnAGe5+24tnyt7GTXSLvvam9lbCVevJxBRggWPBi50911b+tqRmKXdY2YfIowrH/P2ZNTHN/zbR6+NmV3o7s9sOmdNP51cv+p036V2dYnAP0cImqUIF7elCT/kLYmQ1wnJkCySNB1OPMg/REQX3knMLt/nNbNsM7uWeED9emT/XOIh9Wlv977p5NrW5FkyHePrg5l9AtiMmIFC/Nbmufv/NLSpWjXX5k8xsx3c/Ttmtq5PYtbcJtl3b3o1tPs4Ya0/l4iGeQwphryhzRbEEuUOSlFSRBhkdo7Mri8ifrx4MjfOTgjDwwoV+x9DCMa3duh3OVJu5Cn+PH2u/bLEj/1E4gFUvCZ81pr2hVX/WYR66mVkRPpQmm1k9vNCIppuR9LsmIoZckW7k4GPEg+W3YnVymcbjn9806uh3Y3p71JEhNrMtG3U55a+hogk3IyIvntC2r9yXZtyXzX/+0XGNXkDsZy/i3DBu492j4z9iYf0qsQDfYW6e2QKxpftjTF6L1JaVRKr4LbIvWsprSxTm9rcDvTMJzL6avN2+BbhRjGuAkKyijZFb7yJePIfxZhze5tyeQlipjCL8VFSdxMuQpX0mZ2b2Tbuft6I1wLAWmaGVwRklM43wVvA3f9iZr/ximg5M2tLx9hKmh3N98hw9x80HN752ntY8/9OSnFpY3mKlzazpb29qkjhq/wS4Ch3/55FAEsb88zsMsJKPOrhUMVriAfl0kSeDIjvvs32sLa772hmL3P3r5nZCYRPcR2rer8yQv+C8KxI98NDadvNrM6D5mEfMzje5smg6O5/NLNanS2Rj3dCxZdkOMvJZbs3IfAvcfetzWx92nNpFzrwctpHpzrF5mTHt5Lne2OMshyxkoCYWLRxJnCSmX2B+DxvoSFycqpoE76Hp0GMCqMXELOcutyVqzDm3H6YhRP+7CYjgI+5sB3r3SLg+ri/PIdQjleljHMmft6Cu81sY3e/przTIlKmzh2pcI1ah9CVFXlut2XM2FFLxTJqbzN7ltcvozpf+1JfLyUMg13yFAP81sy+SAQwfNIiWCMnadM6wH8Bb0xL9hOBr3kK9azgad6vvl9X16++ZYRWTgYjK70nbdeFkpcTtz9s4xO3N13D/YBzksV+HnHfbkYYJBsNpInOrm2e4aEzheN7qCy8k9Bu9w6Ag4Gr0n1vxKSlLWz7fcSk5a2pzVmMJXuqYv2kVhklNwdzHJym0dX/NLvR3Sckt07/u8HdWzObJX3btoQweBahaN+l4fhOFtWac7Tm/0zHzU/o3bSv9L9nEULwGMbfULsDu3qDdd/CTW9HT/HeFvHf33L3tsxr1wJP8RT1ZeHWclXOF9zj2vfKU5x02S8ilsm/tAjDfXLmbLY4x3OJa7sMkVHq/e5+2cgxRxPW8pxscOV2hevXkwk3xkbXLxtfsDM7d3If74oRT5GKJo1umRsTqronpfY3AIeOTg5q2ma7tjWsFItBVk5WKsZ3PfC/mePr7I1Rarsq8bs0Qv31h7Y2pbYrAKt7ZAGsO+YGGmrdZU8eW3QhP+/zv9Ixa45sL0MYtJradMo0xiTyf9Iv7+oqRMjoKcQM+aPAKhnX4iZKuWDTWHMycl1LSa9G6NnadFgzgJ0qrv3uLe2y8xRXtN2YSBv4DmDjzDbLEYbAS4kV1k6Ed8jmVOipCR3l/YSQuZJwP2rzTplwLTLGdQ2hY3xM6X2jjrPvizFPmaWm8rwdx/AcQn9emauYsQxmx1S8vprZx9I9xpXtjUHoyA8DfkDMfpfp0M/56fexAhHwM48wCNYdPyV1HtvUDn80s6f7xBnIZrRUwk2cQqkSrbvfbWbvSF9aHV0zje1MCEAYn/9zXSJ4YkIuz6TfehIp72rpX8vQknfV4ynamLSkhhOAS83slLT9cmrKtozQeRnlkX3rHUSSoWLf3bRnYBvNU/xH6vMUz8fM9gbeyJi65usWmdeOaGl6OXFddvLxs4VLzKwqrn77trGMUnUtMuhVRshG6o1VjKVK//9ZYoJxEROrNrfSdaVo1QmbirpxSzOmK52Pu++X/nZOsGRmWxDVkZcGivLqb3b3t7W0M2I19QR3P9DM5lTJohLHEd/ZEYTAPpyIQMth2SSb3kDYH/arUSsUXJh53kba1A5PJ27aY4kPBmN1mF7l7pfWtCuE2yGMV84vA7zXG9QV1jHT2MgS8RTCfeuLabvSRc3MXkb8kLdjvLHmHiLKpTKSxupdkLJ0PemhtVU6x8/c/fKm40vtOi+jzOzDhAU7O7TbUrmo1M9rCCH0DW+ok5baXQts4SnVZjrPxXXXw8wOcvcPmNkMr0miU9NuLlG37YGkAtqIqKLRnLqvx7Xog/UoZWNmlxB69ZcQUVajbdrcOa8h8oSMK1PvFVm80vGd1RzJDrNHer971edoGN+lhMH8tNLv9Hpv0d1bZCl8GNjG3TdIqsSz3H2zmuPHuYvV/fZr2l5H2Em+BnzQ3S+3UtmjhnaPJRK8P87dX2wRcLGFux+d02/jzNfdL0sC+O2MPUWuB57hFaG0JdYjnj7LMd6odQ8xQ2qii0UVeuT/9B55VxPbdji2ivuIAn+e/tZiE4s/FmGPjzOzx3mLDy3hjwzx3RU0XUe8X55iiB9yOTvbQ1T/uAteRPhEZwvexKnAZhZ5io8jkq+cQPv30ulaWE3BzfkNa659F6FUYlvCULkNYxOcLnRaKXo3o1lB2Xd9b7rdG7j7HTY+D3JlJr8RnuFRu7CIbLvLmqul2IixcmZ5u+VBeyDh8XBBErxPIAyhtIIAAB8PSURBVNw12ziWWMUXuY1vJh7wkxe+EC4vwH7pg29API0aY5YnIdz63Bz7EAlTVgI+48lYZpH/86qqBma2r7sfAuxiUT57dAyVsw2fRB7itPR9GzGjN8K15XPuXleW5l2EBXa0Ii5QXQl3ZKzZ19HG5yeuOldbGfJjCJVK8dleRvMNOHPkhzLaX90P5WGPvLo7ELleDy9+nC1s4BPTEzapl4prvhSx0rsmjXUjQj9dmQ7RzL5P83XcrmLfn4FvmtnPPcMQVcH3LYJ/OuWkTuPdgfgsxUrs1Lqh9xhXwR1mtiXgSYa8k7FEPU38OxmXPY11JcbcC6sYVRXBmLqobdJxMqVEOh7ufjmlmFb0SNtaJNt/0CIVbBZZWc2SIPsi4aRuwJpm9mZ3P725JXekH+S0ZRrz8Mdcv2L/j4gy0FX0ytLUIKRyos7eROT8/Uc610GEnq9S+HpU3Z1BFL3spWNKN/1cxusCJ5TDdvdHp+MPJNywjmdM9dBamcLdP21m5zMmlPZ09yahuD4TfyjzT0f9D+VBi2i61zKm/82ptFGlT63Vsbr71gBm9k3Cwn5d2t6Q5sxah2aMZRxW8lO3iioZbWoHuq8Ui34/T5RwLxJYvcXMXuDub684fPWkz7bS+9wxvoXQa69GrN7OYvwKpI7DiQfKyhYVSV5JQxZAd5+bcc5xFJMwq4kVyLj291okiy++v82pdzmdQG5KyU8TFWZvSZ2sRSz52oTvMcSysEj7t2vaV5tpjAgOeARjQum1aV9lpjHrkbnK3b+f/nZdPnUpkTOKMeZvSnrfWPwxGYsOJaL/unUWobtrEbH0xdPYieV6Hf/l7s8obR+VdHY5KSwhPs/DtHwuIvopy31rhNcRq4dD3P1WM1uThoKFZrYK8aOfbZHkpRjXMuSVpFm/ELwA7n69RUHNSjx81bvSx0+93GcfNQKEh8OGnow+ZvY1xgxvo5QFe6fxppn9hLDqjHbfsMi89jzie9ve3XNmzJjZaoSPennSURU2PZlUmRCr09OI4KwLidV3bUDYKLnCt099NIis/2XPhmOtPTfvZj4+P8J5yahQRyEQ1yOMUoUB7aWE1X4CfZaHNecpIsGKdk2RYMcTVvyyt0OO8O+cnzSxKfDEjm0eMrPXMFaT6tVk6OfM7CPEA/YU4odyjJmd7O4f69B3K+5+PSF8i+3biHDqOv6LsFWsTkwgCu4BcvIK/Nwi7ejXieuxKxlLZutQt6ynnrjc1yMJITAnrZbWIYqgNkVBQkRBziGqpUBkLKy08I+O0cweNWIfaBpflQfI3wm3xqpK1UW7JxMrpD8Sbq25gveThAfUjYyfdEyQBX0nYaX2V1pkoCuqZvyiboVeOdam36aNuWG9gIr6aO7+7saT98jNa2ZXEsEIv0rbTyByB7cl1jkLeIWncjkWCbNPdvcXVRz7nPR2B8Jvt3D5ejXwa29PSLIdoRccFwnmLUEnFt4Oz4b5lYtbvR2sf2Kdk4lUnG1FM8tt5hJLxEJNdCGwj7cUFTSznwNPLfSqFuWSrvT6vLx7uPuxHca1FhEZdRfhy/lFQi11C/DGNuOjmb3C3U9pOqam3VKMV4H9lAifrq1zltp1rquWdJrvI9IvZpXqSu2+RahwdnP3DdO1v9gbUqmmdj8hJiuF69ZmwMUkQ3DVBMRKbmPunuU2ZmZfIoRooVN9BeGnvQZwq7vvM3L8ssD3GHsYGBEcczvwMm/3bPkFkVWuNYTZzBrD0usmYVYTbFJqV5ueYNx5WoRvkz+ue3tBwM65ea1jprFSu5sI5/770/aSREKeCfrgUptO+WRLx/SNBFuGmIWVl0NN/oS9sfALfgrx4yobYrJm9R37Op34/H9L28sRLmCNXggWPqrvZeIScZuR435GPMCXIfSF+xJh2s8m0gxu3tLPksSPfu5IPwfmfcLJYy11y9Lk4VuETvkthC73T96eS/kKd9/UxrtctuakLk1AKqlSoVgPtzEzOw94oafQdjObReh9X0BERD5x5PjDiYTk+/r4qM6DibSNe7V8rtOJyds/mo5Lx/6JSOR1ImFIHacuq1MjTVYuFrS5mnV2qh5pfzvhSzufpHY4rKHNucXSCeYXwMtJxHE8cFky8DmxrG/SbwKsZKXqCEmHmFPO/d8eyXRmWPiq/jgtd2qxCD19E5FovHjiOWOzqrp2heFrTXf/qJmtQSR+qXM2L9g/43OM9rUS4Qo4l/FCqu1muh+4waKaiBM/rAuKJWeD4eJkwkf1yzSrNx7tySvEosxQsZI63cwObhkbxEzq78QMMedeIvX1TOI6jj4c2oxZ5VVaUWaqzV7Qt1TXA2m2W+hu1yLjM7r7TyzyJazj7uekc8zylkKr3t1tbDVi5VYYoh5F+MU+ZGZV43w+MXOd79mQjv0A9TrpMv8Erjazcxk/6ai6B1ch7tVXE+lXf0gkV7+hqYPJysWCXG+HY6jWYWVJ+BHeRYXwNbNdiZn48UnYXpv2v9HM7nX3E5pO6u4fN7MzyLe4A/w3cL6ZFaVp5gJvzvgMfSLBdiGidbJ//InPk5zNiUi+fxA5X+uczY8kikP2Mf58j0gJeQ55vpgF302vgvMz2+X6qJZdjEatyTm+wqtXqZ8yOJq4R8YFMGQwWrfsNtrrlhW6wt+b2UuIUl2rZ/S1HxGavYaZfYNQGe3R1sjM3khMBlYgDLOrEw/CpnJdfdzGDiGE4fkwP0LzIItAnAnRp0RF7wm/JQ83rpzfzmm0Z7krzvkQce3OSKujVxPy4EBvj84EIH1Xo3mi81ZUnhf7/IrS6zWEX21j1dKGc1VW3iV8cidUASWWmq1VS9OxMwk97JzildFmScKJvDWfb6nNo4gZzSxiefhOYubS1OY7ZFQLqGh3ZXF9Svtq8xsTTvAXE3XlPkkk5cnt6+qe3+nKFfvWy2i3Pxn5YYnZTJHLoXhfbN+b0c+XiEQ/XT9Xa07iqXoRwRbLAhsS+XXnkZGrOLV9DBEht23uPUZ4wSwxcl/V5g9O/1+RSH50J2Hr+HrbfZ/arUr4fm9PzHqbjr0JeCrjqx5vQoRgt+aTGTnX8qSqIg3HLEnYfk4mwt0/DKyWef4vEKvrO4iH4HXA0bnjy6rhNoqF/+k53iHTWKnt7e4+p2J/bThf0/9Kx+xFXIA7GYuw8ox2Wb6wpeNnEkmdn9903op2TyMitK5l/HKoUXmf9GxbApd7RPysRIRZNrpqpSXlq9JrKUKv9U1vyLxvZh8DLvLwkc4mGTk+7O4npe13E4niKzPildrdVrHbfWRZn5bStXh9Csqi/Y2ET+ttxLXPvTc+QTzQv8P476zSwGeTCMOdDJbvWlVuc6m7P6PQFSdd7JVt16Tn+LIrZqQZcpMn0tYtfZ1PqDpnEQ+YPwE/cfcJLqkW7nUbEi6z3/TwpsmmkEulv0sTXkkvzGrfU/iuB/zQ3deu+X9TMMJsd5+g7rCwmG/qIy4sFl4Ll3uD4SwddwsRktiYh2CkTaUvrLfH058GvNY7lBQ3s+uJqqbXUVoqe0upaQvXr52Jp//XCIPHfEGX2fdTU98bufvMhuMKz4r7GfNDdm/3rFiVmF3+C3gssRR9t2cYPRYE1r8qc5WR1+smHSNGr6zcAjb5Ul2Fa9UNlBLMe4th1cwOISJVdwP2IlYgN7r7BxvadHYbs0hWszeh1riayFh3cZ+JWw6lh8kbgDU8JcmpeqiY2cOM5foofwe5933xALuEmD3/lVg9rJMz1lydbyFMLf39Aw0Jkb1fMMLRwLfN7K2eXJssXJ8+R16s9B10iC5J9PGFhRAy1yUDU25J8b96j8qr3tPZ3CJS8EXEzPd5RF7UxkoFPb83PMrOn0FkW3uYyMVbK3itY35YM7uL5sjCqkxd5fP9xiIRzzrufkxaPSzd1MYiOdTHCNXDP0r7m/Iv9wnDLTv4H0Cs3rqwPaHi6WpL+B+irt11hJ3jRzQnEIeYuVa5jb3ezLb2EbexRKeKGXX3RMHovVHBrDQZ2ImxnAt158pJ+N/EDyw8ew5hLC9H2zWcT5bw7fuj7IK7H2pm/yCsvMUP4x/AJzzPKHMroSz/IeOXiE0C73rC4pntC5v4YXp14XIz+yhhDCiPr9HVzMyOd/fXErqw0X1VxxfW220J95kiRLbVKd7MKj0vMpawZxPXcENihvNVC5e9ulDc59CtksiKTf23YeFpsinhQXMMEUH5dcI4VXX8OwmXtp8DhQdCMbP7OPWRnZ3DcMuqCTPbp4eq4tb0ebp4ccwkKobsSnia5LI2kWWscBs7ipLbWE2brhUzintiZULddl7a3pow5LYJ375JcrKx8Ne/w90/mraXJj7/TcBncs/TKHzTcu1vxfLawp91e8KY8zl3f6DX6Gtw9y8AX0gfxrzF7WWE29NrifTKYUXgRos6Ytm+sB51wGYTBr3cqgpPT3+fWz4VLa5mjJTwST+cpgqyHyBCut/j3VMmlsNIlyLGPI+WJD7EvVAkZflb0qPX5hz2jvlhPdVCK7DISVtOjPO7llO8nDDiXJnO97ukzqrjjUQC/3+k1de3zWyuu38WGkOne4fhJrJnziV1RRfXquJ/D5nZSma2RMffcFe3MYD/S7PDU4Gz0yqm9vsq7gkz+wGxKv192l6VWAU34v2T5HShKJlVTFg+QahunkKo37JCjNtmvicRN+7fLWLaTyacnZ9CuEBV5lvog1XkaLCSP2Hbkt0rSrRksH+PNljUOjuUEPJrpmtzYJPQdvdnd+zj/YQgnW1mRVSPEQ7otbMVH0sKs5aFi979FiV6NgKO81JRwoq242aiFj7FtXkdLKW9dPdT06zm/nSeB9NsuK5dL8OUhVvPZ4jZ9V8IYXAzFYmVRnjA3d1SIVELN6cmZhaqBnf/dbp+306TkVrhW3wOM9sxCYHy2HesbtWbQrjPI9O1aoRfAxcm+0VZddb0O+vqNoa7vzy93T/p0JclrzjlXB8fnXknUSChEgvXufM9ylgZoap8JfE5d/d2t9MuzCxNbHYGvuQRQXmKmV2dfRZvdqW4tvT+UCKhCYSbVWMpm64vQte1HzFr+yXhK/m/xI/rKxntVwI+ReiuziteGe0eSyzRt6XCZaqmzTziJuriprMS8cT8Qdp+IrBHRl8H97yeVxMP17WJbHSfAX7U8RzW9LkolfBhpJzP6PbI/67KOa7mM61UtCeWu1/IaPeedO1vJWa1FwN7NRx/HiMueulaHgc8lNFfVXmqys9J5Jm4O70eLL2/B7g7o69HkUrUp+2ZwCMz2u1X9cpo18VtbAZwfc/790hCfbAH4c55OnBEw/HXEzXoIHzq5xEueM8n0mV2HkNLX7PS+5uArcr/yz1P28y3/JTfhrSU9Mi21dK0G55mrhZhlpv4WI6G/SktIxr4BhGeuS2l8MymBma2EyGwzyc+6xFm9l53/3ZLXw+6+99HrkHbkvHYNMbCUPnLNN5jW9qVExoVaocPeftM/2GPGejLidy3R1hL7tsRy/sMYoXTlNTIat5XbZfpY5iCuO5/sogsNHc/2yLdYPXgzNYGHuthT3gBIdTWI37ITe50uzESNOOh59zNokpzXX8vJgorrjai711m9Hyl807WnnIuIWAKo+BsQg+7ZVOjjPunjn8R+v2lgLXNbG2vsQkkOXGNVZSQb8Pd35Hu3UIt9yV3/25Dkwd9LKnNtsQq7y9EBeXcrHy5nEjYpv5M5Fv5Gcy/36YspeR5ZnYScbGXJym/k/5lSvW9JeaMnPsBmst8F/QJz/wgkUXtj0ARXnsOEUTSxPVmtguRFHwdIsiisvRQiZXd/QQzey+AR1LwnKip51lkNXs9oaP+Khkl54lk1K8mHkKFOqEt921ZT/kgEWrZlEvYa95XbZfpmx/272mJewFwnEVkYVOE22Gk7GXufjZwNoCZbZr+V2XwwxvyTbdcj98R13A7xleluIeIlJsOlvKSN4aHnro2XaaZHebu+1hNZj9vUJ1ZjdsYzTaBVYnQ88sYr97IyTFyEXEfOmMJgOp4OMmluwjvnvJDeXZGX9l4RNOeS3y2szxNeYkJS2PuiTJtwncfQqexKlFltXiyrEKLG8ck6JOjAfqFZ87w8eWQ/kJcwDb2Ij7//YSa5EzCLamJe5OhqNA7bkb8KBtx913MbGfCmvpPIoFNTnL1PYkVwMfd/TaLvBWNBTs9DIlLMKZbazMm1glRI/SxdfQ1TG1PzLz2IWany9JcQmiuV3iTuPsVyZA2pXhUorjGzE7wDqkFJ8m9ZraJp8APi2Ce+xqOPz797Zz4nY5uY4leM+weq9KPEPfSTCLxzw3pPM8h1E1TikcRh9F9tQFMVXQKsrBIlbcVcLvXFOibCtINVORo+KlnKMvNbFti+r8GUcF0GWB/Tzk7a9p8ijBEFYladiZ02W2ZpJ6aM6aRNpsS6RqfRCzlVyOyL7WpAtYhgiuuI8o43Qi8y90ba8D1IRmWvkYYKYy4lrvXLSutR8HIkfaVhqnRfaX/HeQj6T6r9pX+d4vXBwLV/m+ypHvxo4xFnWU57ffsazPCnbDwIFiVKG5b+VDrowIotb3c3TdLRqVneBhzxxWunCosMge+YHRV6g3Z2ix8ue/3cDF7IuHnfhMhQxaKgJ9xtCiWf0Bku4f4Un9PpPK7kcjzOmVK7JF+O+doqDlP5RgJI9Qz0/sdiETbnyGenmtlnPfHxJf6UeBJHcazBJFD4inAEpltbgKel94b8G7ghox26xDqkxuJJ/+tRP7UpjbzKOVkIGbArXk1iIdI676KY7INUw3HN+W5OJHI9zu6//XAt6b6vi2d/xbioW7T1UepryUJddKGRN7bR9CQo4TxRtJTOvb1XaIo7v5EUqnv0WLEJVQTlxM66QeISNIcQ+J1I9szRveN/H8/4BJi9nswoSL9SBrnB6f7e+j13bVcgBtK7z9AKLEh0uNNqbdDqZ+9gD8TkTPXEjO+Xn0RM/Sq/T+gIuEG4Yj//cxzr0Loei9MY/xQx7FtDZyecdwyFfvWyWh3AaH7upaYge0PHNDSZsJ1zrn2PYToi4nVyZ1Era7idSxwWcXxbyYl0WEsqc6VhNHyxIZ+HkvoDc9nzHvmJ4SecpXpuH9Tvz8mVFrTcv5JXvurqt736Pc5hG67cRKRhOHa6fubSajDDso4/6cY83bYgzCSfrLh+OvS+R9JGFaXSftnT5esmuyrTedb1ls9j+Rf6u73WMRFTwd7E7Ov7BwNDdRZ3Of6JHWB7v4H4PDku7gv8ZSdoPdNOqejiJn8qcRT+WvETdFkqd/X3Q9x97srluJ70l4GZ7ZHbmTzyGGwv0VS8v0a2lxhZkczphd8DQ3lzPtY9xNdDVMnEVb9g4mw2PnH+3id/Tjc/U5gS4vgoCLh9w/d/by6NlPEvsCPksE3N9qyE9a/Pl2TkbSpv8K9dEOIfMC5bd39FjOb6REsc4yZtRmncff32lh1ZSPP2+Eh4J9m9itPFS/c/b5plFWTok343mGRLez/iMQuZwBYRHflVI3tQ58cDXXU3VxNZcNbLaNmtgGhH34lYaT7FqEOqOIwYoZ8MTHju4yYgbb9EF/FWIDD+xnvbvci2oXvv9IP5pcWZet/S4RsNvFWIqz2ncQN/1Nqqisneln3vaNhyt3vIqzYO1pUEC7sAT8jo5agRxWUH7cdN4V8nFhmL0V+tGVX+tan29giaMeYGMDjXqOX9v5uY/9MRtxrksvX7wnf5BwuJCaAOd4OD5jZIz1sIfMjQC3KEi2UwretjNDKRKz0qkQI6Vlp/9ZE+GUfi2nzgGLmtR6RO6F11mD9MqidSARgfHlk/+uJkic7t4zxUkJ1cT6Rca22ppeVMl2l7VsJvXLjrMPGZ8gaPce47Zr2mxG5CZYjdNPLEkEyE6y0kzHCpPaPyBGiFe06GabM7O3Ew6EIZX4ZcV82PSAWOJZK+yygvnrVp+vZ13mM1X3LchuziAq8k3gI/TcxMz/KxxfkrWo36u3wbKDW28FKEZYj+1ckKr/kVMFYoPRKKTmdWCRBmYD3dwqv6uOxhPHgAcZmbJsSN8jLk0qhqt0s4CCihPntJBcrIlnLB6sEUBK25WxPh5W33b0yNNRKKQltJD3h6PZkGenrFHfvFAvf17pvkQZ0B8KQ0nojmtm1wJaeLNcWOUAu8mnIQTsZLPIAn1dMVqapj13d/esWuZOr/HWnTMVR6vM5VfurVBBm9jKigsjn0valxMrLifpsjb70fbwdFjXaEuv0qu45GaZSyDb00VcX+CnC2Limj0XgLUP4TB5K6KtHuZCoXlu17dTH5TctD2vVJj2/s7JuvLE+WQ2H0UGIlriDCMfMbWOMt0MUOYcXNt4O7GuRbCY7L3JHiqV7VWrMaZlRddHzEnrvV5W2lyTUAUsTk5W2QKa+PviLDG063y1oqO45HaQn3L5MrIs05cmXe+gCtwXWLQuLZBB7K+ESNkH4uvtrLUKCt++yPPSGpOct9PnOehlhSnQVogVZhikzm+UR3ns8cImZFdfx5YTxcqHCF0AKVlJK06rJikXipynHzDYnvFQ2IFaJM4kyTlUPlSXc/Y7S9gUeyWj+au2JjSDqqp3JeB/8ThVWFnbadL4zGavuuRGZ1T0nNaCeJbQXBGZ2s7tXZlZq+l/6/8+8Y2azPvT5zizCnO8lzbKJSDrIVx9sRqgdOln303f9DyZW9zhg5LiyWmQzQv9nhPP85U19DIFF1eOr3f1ei8KwmxD5NXrr1Sv6+AXwX54KD5T270m4PTaWXurZ5xXEbPZkQk23G+H2OMHA1xLg8qu68VlUN7+QCF9+KWPeDj9t8XZY9PB8v74lCevqn2jICDXZF8mpn/EZ1X4yXf11HNupwG4V+3clQhqb2n6I0PWuShgdlqHCh3eKx7ugvrOziCTXRSWG/cjLkHVF5vl7+6MOdJ9cSwiMjdP7vaf6HiZc/H5Jyeeb8Iq5jtC1TsfnuqL4fKV9F9Uc+w2qA1zeTLNv9qGEb/ZfCWPbQURx0AmFVRf1V2slC4uSyi8hZlJzCWf4tmzyk6FvCe0FwduB75jZ6whDnRPW39nEEriJoiR92SXNiQi+KWWA72wFzywaOMI5ZvZCbzdMrWQV+Z4LfBqMS5PkQXf3ZHT6rEfCp8ZQ7K64+4+STvl0M9ueyK29GZHe8K6p7KtEF7ex/wZOtUhAVRQcfRoxIdi+rgNP1U9SP5sS2dleB3zZzP7mLUVZFyXa1A6Tqu7Za0A9cjQsaMxsG0InbUQUYGMRzAXJQN9ZL+u+ZRbsNLPfE4EqlfprXwBG2i4kHfYZRDDMVsTK42p3f/I09PUsYkV2EbCTN7g9TkFfnd3GSr8ViN9KVoBL8s/dgij1tAXhMnmdZ1Y/WRRoE76Tqu45VVjUtjpsQfQ1nVhkgXoi4w2JJ0xxHwv8O8sVopM4/5S61k03FtFnuxA+4D8zsznAc909Jztfbh/lorZLEtf9Iabhe56s21jHvr5ECOt7CIPxJUQWtemazQ/GQufnW4WZ3e7uU748X5CY2YeAFxIlb84kIpQucPfGaq2LM7mGqZygkoWV5OT/F18Ufmg1mNmFRKa0O9L21UQO36WBY9z9eVPY1xlE3urridn8xfTzpFnoWVT85hZGX86u7Ewk0/m9R+XhjcmsHr2wY2bPLNyHzGxXM/t0mu21cRShR9yYcDv7DWN5JcpM2Y97OjGzzc3sfDP7jpk91cyuJ4TInWb2oqHHNwkq3cbSQzI3VDgLd38RobsuomffTVT+PsvMFir10mRZVITv4vDUu88j8ceDFpVz/0C/gIaFkVwhOsqDaUZTGKY+SwSxjMO7V2EeiiMJ6/yJRErDN7j7KoTe9+AhBzZJli9vuPs7SpsrTXVnHlxP+PWeTrierUV1ENMiy0IjfM3sHjO7u+J1D5ERbFHnKosS2l8lktFcxpgVeFEnS4hWcI9FleZdgR8mH+XpSti0IJjl7md5ZKD7g6c8Gu5+08DjmiyXWlQHHoeZvZn2hDedMLN3mtk3zewOIrHTtkRFlR2AFaayr6FZJHS+ixsWhfaW8VT6ZVGnr3V/QRimFiS2APNxLEgsEmydShhUJ7iNeYTrT1VfnyZ0vRf6+NLxix0SvgsQM3sVkdHs42a2BlFUc9rKMS0opkKILiaGqaZIwaXcfVGe1fd2GxPVSPguIMzsSGJJvZW7b2BRTPNMd99s4KFNKTlCNOUI+AQRxfRRQj+8IqEG283dz1gQYxViSBYane9/AFu6+5uJ6ruFEWm6Em0vECZh3V9cDVNCZLNYuDotIvzborKEA1hUgl4oM+x34EiiasKyhBB9sbtfkoJJTiRVPqlglo8l5j+wbJgyWxy8CoVoRzPfBcfngFOIPAUHEAUuPznskCZNX+t++aFz38j/pAcT/xFo5jvNmNmPgLe5+3FmNg94PmGA2XFB5F2YZvoK0V6J4oVYnJDBbZqxqEX1MSLp9yHeo9bZwsribt0XYjqR8F0ApNDbjxBVh49nfOLwhS0dohBiASC1w4Lh38QMcUki8mtRN7QJISaJhO80k1yuPk0UytzE3f/Z0kQI8R+A1A7TjJn9DHiLT2PdOyHEooeErxBCDID8fIUQYgAkfIUQYgAkfIUQYgAkfIUQYgAkfIUQYgD+P5DS/6F28dtlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='YlGnBu')\n",
    "sns.heatmap(test_df.isnull(),yticklabels=False,cbar=False,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dropna(inplace=True)\n",
    "df.shape\n",
    "test_df['Utilities']=test_df['Utilities'].fillna(test_df['Utilities'].mode()[0])\n",
    "test_df['Exterior1st']=test_df['Exterior1st'].fillna(test_df['Exterior1st'].mode()[0])\n",
    "test_df['Exterior2nd']=test_df['Exterior2nd'].fillna(test_df['Exterior2nd'].mode()[0])\n",
    "test_df['BsmtFinType1']=test_df['BsmtFinType1'].fillna(test_df['BsmtFinType1'].mode()[0])\n",
    "test_df['BsmtFinSF1']=test_df['BsmtFinSF1'].fillna(test_df['BsmtFinSF1'].mean())\n",
    "test_df['BsmtFinSF2']=test_df['BsmtFinSF2'].fillna(test_df['BsmtFinSF2'].mean())\n",
    "test_df['BsmtUnfSF']=test_df['BsmtUnfSF'].fillna(test_df['BsmtUnfSF'].mean())\n",
    "test_df['TotalBsmtSF']=test_df['TotalBsmtSF'].fillna(test_df['TotalBsmtSF'].mean())\n",
    "test_df['BsmtFullBath']=test_df['BsmtFullBath'].fillna(test_df['BsmtFullBath'].mode()[0])\n",
    "test_df['BsmtHalfBath']=test_df['BsmtHalfBath'].fillna(test_df['BsmtHalfBath'].mode()[0])\n",
    "test_df['KitchenQual']=test_df['KitchenQual'].fillna(test_df['KitchenQual'].mode()[0])\n",
    "test_df['Functional']=test_df['Functional'].fillna(test_df['Functional'].mode()[0])\n",
    "test_df['GarageCars']=test_df['GarageCars'].fillna(test_df['GarageCars'].mean())\n",
    "test_df['GarageArea']=test_df['GarageArea'].fillna(test_df['GarageArea'].mean())\n",
    "test_df['SaleType']=test_df['SaleType'].fillna(test_df['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape\n",
    "##HAndle Categorical Features\n",
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']\n",
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "main_df=df.copy()\n",
    "final_df=pd.concat([df,test_df],axis=0)\n",
    "final_df.shape\n",
    "final_df=category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>20.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          20         80.0    11622            5            6       1961   \n",
       "1          20         81.0    14267            6            6       1958   \n",
       "2          60         74.0    13830            5            5       1997   \n",
       "3          60         78.0     9978            6            6       1998   \n",
       "4         120         43.0     5005            8            5       1992   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0          1961         0.0       468.0       144.0  ...     0     0    1   \n",
       "1          1958       108.0       923.0         0.0  ...     0     0    1   \n",
       "2          1998         0.0       791.0         0.0  ...     0     0    1   \n",
       "3          1998        20.0       602.0         0.0  ...     0     0    1   \n",
       "4          1992         0.0       263.0         0.0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train=final_df.iloc[:1422,:]\n",
    "df_Test=final_df.iloc[1422:,:]\n",
    "df_Train.head()\n",
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shailesh Nanisetty\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)\n",
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras\n",
    "from keras import backend as K\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shailesh Nanisetty\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Shailesh Nanisetty\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Shailesh Nanisetty\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\Shailesh Nanisetty\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\Shailesh Nanisetty\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1137 samples, validate on 285 samples\n",
      "Epoch 1/1000\n",
      "1137/1137 [==============================] - 1s 549us/step - loss: 136049.2999 - val_loss: 50067.2374\n",
      "Epoch 2/1000\n",
      "1137/1137 [==============================] - 0s 302us/step - loss: 49520.4009 - val_loss: 46819.5507\n",
      "Epoch 3/1000\n",
      "1137/1137 [==============================] - 0s 286us/step - loss: 45830.9929 - val_loss: 43770.9659\n",
      "Epoch 4/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 43070.5880 - val_loss: 41420.4890\n",
      "Epoch 5/1000\n",
      "1137/1137 [==============================] - 0s 283us/step - loss: 39574.9188 - val_loss: 39598.2712\n",
      "Epoch 6/1000\n",
      "1137/1137 [==============================] - 0s 268us/step - loss: 36741.0049 - val_loss: 37186.5482\n",
      "Epoch 7/1000\n",
      "1137/1137 [==============================] - 0s 280us/step - loss: 34075.1955 - val_loss: 35144.5390\n",
      "Epoch 8/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: 32031.8393 - val_loss: 33961.3875\n",
      "Epoch 9/1000\n",
      "1137/1137 [==============================] - 0s 273us/step - loss: 30524.5025 - val_loss: 32997.8082\n",
      "Epoch 10/1000\n",
      "1137/1137 [==============================] - 0s 266us/step - loss: 29334.1875 - val_loss: 32169.5302\n",
      "Epoch 11/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 29126.6264 - val_loss: 31859.3232\n",
      "Epoch 12/1000\n",
      "1137/1137 [==============================] - 0s 300us/step - loss: 28199.6052 - val_loss: 31882.3272\n",
      "Epoch 13/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 28066.6908 - val_loss: 31239.9251\n",
      "Epoch 14/1000\n",
      "1137/1137 [==============================] - 0s 281us/step - loss: 27684.7339 - val_loss: 31832.7983\n",
      "Epoch 15/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: 27560.3008 - val_loss: 31152.8355\n",
      "Epoch 16/1000\n",
      "1137/1137 [==============================] - 0s 255us/step - loss: 27093.7911 - val_loss: 31484.5596\n",
      "Epoch 17/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: 26842.7400 - val_loss: 30745.2315\n",
      "Epoch 18/1000\n",
      "1137/1137 [==============================] - 0s 256us/step - loss: 26929.4740 - val_loss: 30285.3255\n",
      "Epoch 19/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 26675.2742 - val_loss: 30297.9582\n",
      "Epoch 20/1000\n",
      "1137/1137 [==============================] - 0s 306us/step - loss: 26553.3758 - val_loss: 30208.6055\n",
      "Epoch 21/1000\n",
      "1137/1137 [==============================] - 0s 283us/step - loss: 26470.9601 - val_loss: 31306.5449\n",
      "Epoch 22/1000\n",
      "1137/1137 [==============================] - 0s 322us/step - loss: 26239.8499 - val_loss: 31226.5326\n",
      "Epoch 23/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: 26383.8625 - val_loss: 30827.2408\n",
      "Epoch 24/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 26302.0538 - val_loss: 29905.7215\n",
      "Epoch 25/1000\n",
      "1137/1137 [==============================] - 0s 294us/step - loss: 26194.9487 - val_loss: 29760.9843\n",
      "Epoch 26/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 26207.4052 - val_loss: 30751.1376\n",
      "Epoch 27/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: 25991.9500 - val_loss: 29754.5355\n",
      "Epoch 28/1000\n",
      "1137/1137 [==============================] - 0s 293us/step - loss: 26110.0450 - val_loss: 30470.1009\n",
      "Epoch 29/1000\n",
      "1137/1137 [==============================] - 0s 325us/step - loss: 25851.3630 - val_loss: 29958.3712\n",
      "Epoch 30/1000\n",
      "1137/1137 [==============================] - 0s 281us/step - loss: 26015.2370 - val_loss: 31699.6836\n",
      "Epoch 31/1000\n",
      "1137/1137 [==============================] - 0s 287us/step - loss: 26044.2188 - val_loss: 29558.8956\n",
      "Epoch 32/1000\n",
      "1137/1137 [==============================] - 0s 325us/step - loss: 25924.4409 - val_loss: 29516.6047\n",
      "Epoch 33/1000\n",
      "1137/1137 [==============================] - 0s 287us/step - loss: 25736.8483 - val_loss: 29966.0706\n",
      "Epoch 34/1000\n",
      "1137/1137 [==============================] - 0s 281us/step - loss: 25623.6478 - val_loss: 29918.7449\n",
      "Epoch 35/1000\n",
      "1137/1137 [==============================] - 0s 314us/step - loss: 25671.1684 - val_loss: 31624.4614\n",
      "Epoch 36/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 25692.4610 - val_loss: 29823.1586\n",
      "Epoch 37/1000\n",
      "1137/1137 [==============================] - 0s 281us/step - loss: 25654.6443 - val_loss: 30308.2816\n",
      "Epoch 38/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 25628.9424 - val_loss: 29216.0467\n",
      "Epoch 39/1000\n",
      "1137/1137 [==============================] - 0s 338us/step - loss: 25555.7284 - val_loss: 31269.4727\n",
      "Epoch 40/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: 25709.9179 - val_loss: 29532.0458\n",
      "Epoch 41/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: 25302.8164 - val_loss: 29311.2512\n",
      "Epoch 42/1000\n",
      "1137/1137 [==============================] - 0s 320us/step - loss: 25448.6286 - val_loss: 29484.5445\n",
      "Epoch 43/1000\n",
      "1137/1137 [==============================] - 0s 274us/step - loss: 25854.6035 - val_loss: 31162.0396\n",
      "Epoch 44/1000\n",
      "1137/1137 [==============================] - 0s 280us/step - loss: 25390.1608 - val_loss: 29264.0437\n",
      "Epoch 45/1000\n",
      "1137/1137 [==============================] - 0s 319us/step - loss: 25235.6165 - val_loss: 30104.6521\n",
      "Epoch 46/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: 25072.4697 - val_loss: 29143.5764\n",
      "Epoch 47/1000\n",
      "1137/1137 [==============================] - 0s 263us/step - loss: 25170.5127 - val_loss: 29701.0451\n",
      "Epoch 48/1000\n",
      "1137/1137 [==============================] - 0s 342us/step - loss: 25031.9628 - val_loss: 29193.9007\n",
      "Epoch 49/1000\n",
      "1137/1137 [==============================] - 0s 273us/step - loss: 24937.9728 - val_loss: 30288.4015\n",
      "Epoch 50/1000\n",
      "1137/1137 [==============================] - 0s 274us/step - loss: 24922.3051 - val_loss: 29294.0620\n",
      "Epoch 51/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 25012.8328 - val_loss: 28868.2634\n",
      "Epoch 52/1000\n",
      "1137/1137 [==============================] - 0s 321us/step - loss: 24934.5620 - val_loss: 29968.5893\n",
      "Epoch 53/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 24931.2857 - val_loss: 31416.7522\n",
      "Epoch 54/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 24773.7975 - val_loss: 28661.7846\n",
      "Epoch 55/1000\n",
      "1137/1137 [==============================] - 0s 303us/step - loss: 24952.5909 - val_loss: 29956.8056\n",
      "Epoch 56/1000\n",
      "1137/1137 [==============================] - 0s 255us/step - loss: 24289.9830 - val_loss: 30148.5682\n",
      "Epoch 57/1000\n",
      "1137/1137 [==============================] - 0s 267us/step - loss: 24833.6457 - val_loss: 29359.3555\n",
      "Epoch 58/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 24812.6339 - val_loss: 29247.3165\n",
      "Epoch 59/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 24779.8840 - val_loss: 28558.2372\n",
      "Epoch 60/1000\n",
      "1137/1137 [==============================] - 0s 260us/step - loss: 24543.1202 - val_loss: 28562.2246\n",
      "Epoch 61/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 24482.4865 - val_loss: 29028.2936\n",
      "Epoch 62/1000\n",
      "1137/1137 [==============================] - 0s 215us/step - loss: 24385.8216 - val_loss: 28529.5072\n",
      "Epoch 63/1000\n",
      "1137/1137 [==============================] - 0s 336us/step - loss: 24706.0376 - val_loss: 29118.6637\n",
      "Epoch 64/1000\n",
      "1137/1137 [==============================] - 0s 296us/step - loss: 24456.0100 - val_loss: 28668.8773\n",
      "Epoch 65/1000\n",
      "1137/1137 [==============================] - 0s 314us/step - loss: 24572.5853 - val_loss: 29628.6298\n",
      "Epoch 66/1000\n",
      "1137/1137 [==============================] - 0s 361us/step - loss: 24481.4566 - val_loss: 28645.5396\n",
      "Epoch 67/1000\n",
      "1137/1137 [==============================] - 0s 290us/step - loss: 24351.8838 - val_loss: 29921.4654\n",
      "Epoch 68/1000\n",
      "1137/1137 [==============================] - 0s 303us/step - loss: 24381.2852 - val_loss: 29168.9581\n",
      "Epoch 69/1000\n",
      "1137/1137 [==============================] - 0s 359us/step - loss: 24092.0368 - val_loss: 29301.5547\n",
      "Epoch 70/1000\n",
      "1137/1137 [==============================] - 0s 295us/step - loss: 24143.2231 - val_loss: 30092.0781\n",
      "Epoch 71/1000\n",
      "1137/1137 [==============================] - 0s 350us/step - loss: 24388.7977 - val_loss: 28805.7231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "1137/1137 [==============================] - 0s 329us/step - loss: 23948.5961 - val_loss: 28434.6874\n",
      "Epoch 73/1000\n",
      "1137/1137 [==============================] - 0s 286us/step - loss: 24198.8012 - val_loss: 28922.8418\n",
      "Epoch 74/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 24000.1250 - val_loss: 28283.7279\n",
      "Epoch 75/1000\n",
      "1137/1137 [==============================] - 0s 307us/step - loss: 24102.2133 - val_loss: 30070.2765\n",
      "Epoch 76/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: 23859.0032 - val_loss: 28296.0587\n",
      "Epoch 77/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 23850.3599 - val_loss: 30082.4726\n",
      "Epoch 78/1000\n",
      "1137/1137 [==============================] - 0s 295us/step - loss: 23773.8317 - val_loss: 28248.8759\n",
      "Epoch 79/1000\n",
      "1137/1137 [==============================] - 0s 274us/step - loss: 24054.0848 - val_loss: 28904.3221\n",
      "Epoch 80/1000\n",
      "1137/1137 [==============================] - 0s 254us/step - loss: 23737.6213 - val_loss: 28295.7005\n",
      "Epoch 81/1000\n",
      "1137/1137 [==============================] - 0s 269us/step - loss: 23729.7599 - val_loss: 28335.2970\n",
      "Epoch 82/1000\n",
      "1137/1137 [==============================] - 0s 300us/step - loss: 23876.5915 - val_loss: 28050.1468\n",
      "Epoch 83/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 23799.6755 - val_loss: 28547.9394\n",
      "Epoch 84/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: 23605.3617 - val_loss: 28436.1210\n",
      "Epoch 85/1000\n",
      "1137/1137 [==============================] - 0s 281us/step - loss: 23816.0670 - val_loss: 29005.9762\n",
      "Epoch 86/1000\n",
      "1137/1137 [==============================] - 0s 274us/step - loss: 23623.6358 - val_loss: 28443.2487\n",
      "Epoch 87/1000\n",
      "1137/1137 [==============================] - 0s 282us/step - loss: 23789.3370 - val_loss: 28848.2348\n",
      "Epoch 88/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: 23907.5626 - val_loss: 28665.7444\n",
      "Epoch 89/1000\n",
      "1137/1137 [==============================] - 0s 287us/step - loss: 23410.3162 - val_loss: 28137.4131\n",
      "Epoch 90/1000\n",
      "1137/1137 [==============================] - 0s 275us/step - loss: 23469.7910 - val_loss: 29418.6369\n",
      "Epoch 91/1000\n",
      "1137/1137 [==============================] - 0s 268us/step - loss: 23530.7344 - val_loss: 27759.6722\n",
      "Epoch 92/1000\n",
      "1137/1137 [==============================] - 0s 280us/step - loss: 23402.6804 - val_loss: 28394.8638\n",
      "Epoch 93/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: 23514.7235 - val_loss: 28126.0928\n",
      "Epoch 94/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 23633.3928 - val_loss: 29470.3466\n",
      "Epoch 95/1000\n",
      "1137/1137 [==============================] - 0s 267us/step - loss: 23482.2815 - val_loss: 27811.4749\n",
      "Epoch 96/1000\n",
      "1137/1137 [==============================] - 0s 324us/step - loss: 23455.3358 - val_loss: 28719.0058\n",
      "Epoch 97/1000\n",
      "1137/1137 [==============================] - 0s 281us/step - loss: 23295.1776 - val_loss: 28329.0046\n",
      "Epoch 98/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 23340.6059 - val_loss: 29315.1433\n",
      "Epoch 99/1000\n",
      "1137/1137 [==============================] - ETA: 0s - loss: 23968.375 - 0s 292us/step - loss: 23685.7411 - val_loss: 28009.1092\n",
      "Epoch 100/1000\n",
      "1137/1137 [==============================] - 0s 323us/step - loss: 23145.8081 - val_loss: 27936.0074\n",
      "Epoch 101/1000\n",
      "1137/1137 [==============================] - 0s 269us/step - loss: 23171.0690 - val_loss: 29874.0342\n",
      "Epoch 102/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: 23149.6703 - val_loss: 27875.6421\n",
      "Epoch 103/1000\n",
      "1137/1137 [==============================] - 0s 261us/step - loss: 23299.6711 - val_loss: 27979.6102\n",
      "Epoch 104/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 23080.4547 - val_loss: 28161.3663\n",
      "Epoch 105/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 23312.9568 - val_loss: 28166.0728\n",
      "Epoch 106/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 23244.0177 - val_loss: 28515.5169\n",
      "Epoch 107/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 23111.5927 - val_loss: 27660.6595\n",
      "Epoch 108/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 23058.7775 - val_loss: 27603.2140\n",
      "Epoch 109/1000\n",
      "1137/1137 [==============================] - 0s 324us/step - loss: 23171.4921 - val_loss: 28004.0459\n",
      "Epoch 110/1000\n",
      "1137/1137 [==============================] - 0s 250us/step - loss: 23387.1636 - val_loss: 28744.4855\n",
      "Epoch 111/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: 23303.8815 - val_loss: 27750.9870\n",
      "Epoch 112/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 22908.3946 - val_loss: 28056.3579\n",
      "Epoch 113/1000\n",
      "1137/1137 [==============================] - 0s 305us/step - loss: 22960.1131 - val_loss: 27448.7335\n",
      "Epoch 114/1000\n",
      "1137/1137 [==============================] - 0s 254us/step - loss: 22994.7718 - val_loss: 27517.4450\n",
      "Epoch 115/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 23006.1380 - val_loss: 27495.8600\n",
      "Epoch 116/1000\n",
      "1137/1137 [==============================] - 0s 311us/step - loss: 22802.6542 - val_loss: 27497.5653\n",
      "Epoch 117/1000\n",
      "1137/1137 [==============================] - 0s 260us/step - loss: 23110.9666 - val_loss: 27597.0590\n",
      "Epoch 118/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 23043.5214 - val_loss: 27477.4116\n",
      "Epoch 119/1000\n",
      "1137/1137 [==============================] - 0s 275us/step - loss: 22989.1254 - val_loss: 28299.4509\n",
      "Epoch 120/1000\n",
      "1137/1137 [==============================] - 0s 295us/step - loss: 22710.8992 - val_loss: 27351.9729\n",
      "Epoch 121/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 22781.6353 - val_loss: 27354.7872\n",
      "Epoch 122/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 22669.5351 - val_loss: 28085.0282\n",
      "Epoch 123/1000\n",
      "1137/1137 [==============================] - 0s 297us/step - loss: 22952.3677 - val_loss: 27341.9265\n",
      "Epoch 124/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: 22688.9540 - val_loss: 27469.5145\n",
      "Epoch 125/1000\n",
      "1137/1137 [==============================] - 0s 289us/step - loss: 22811.6828 - val_loss: 27325.5695\n",
      "Epoch 126/1000\n",
      "1137/1137 [==============================] - 0s 293us/step - loss: 22634.5186 - val_loss: 27527.5346\n",
      "Epoch 127/1000\n",
      "1137/1137 [==============================] - 0s 293us/step - loss: 22824.4876 - val_loss: 27415.1102\n",
      "Epoch 128/1000\n",
      "1137/1137 [==============================] - 0s 288us/step - loss: 22631.8832 - val_loss: 27399.4111\n",
      "Epoch 129/1000\n",
      "1137/1137 [==============================] - 0s 287us/step - loss: 23093.6691 - val_loss: 27493.3581\n",
      "Epoch 130/1000\n",
      "1137/1137 [==============================] - 0s 296us/step - loss: 22706.7495 - val_loss: 27536.7783\n",
      "Epoch 131/1000\n",
      "1137/1137 [==============================] - 0s 300us/step - loss: 22713.2562 - val_loss: 27357.5614\n",
      "Epoch 132/1000\n",
      "1137/1137 [==============================] - 0s 287us/step - loss: 22479.6346 - val_loss: 27144.4040\n",
      "Epoch 133/1000\n",
      "1137/1137 [==============================] - 0s 316us/step - loss: 22320.3645 - val_loss: 27268.4790\n",
      "Epoch 134/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: 22814.4314 - val_loss: 27735.3102\n",
      "Epoch 135/1000\n",
      "1137/1137 [==============================] - 0s 296us/step - loss: 22471.0713 - val_loss: 29755.7068\n",
      "Epoch 136/1000\n",
      "1137/1137 [==============================] - 0s 308us/step - loss: 22544.5737 - val_loss: 28065.4234\n",
      "Epoch 137/1000\n",
      "1137/1137 [==============================] - 0s 286us/step - loss: 22549.3546 - val_loss: 28743.9406\n",
      "Epoch 138/1000\n",
      "1137/1137 [==============================] - 0s 282us/step - loss: 22818.0855 - val_loss: 27217.5206\n",
      "Epoch 139/1000\n",
      "1137/1137 [==============================] - 0s 293us/step - loss: 22380.1470 - val_loss: 27135.2876\n",
      "Epoch 140/1000\n",
      "1137/1137 [==============================] - 0s 334us/step - loss: 22546.0988 - val_loss: 27710.1100\n",
      "Epoch 141/1000\n",
      "1137/1137 [==============================] - 0s 293us/step - loss: 22346.0755 - val_loss: 27774.9128\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 278us/step - loss: 22396.2361 - val_loss: 27009.5166\n",
      "Epoch 143/1000\n",
      "1137/1137 [==============================] - 0s 293us/step - loss: 22222.2517 - val_loss: 27332.6513\n",
      "Epoch 144/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: 22282.7489 - val_loss: 27191.5817\n",
      "Epoch 145/1000\n",
      "1137/1137 [==============================] - 0s 276us/step - loss: 22402.5280 - val_loss: 27458.6266\n",
      "Epoch 146/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: 22575.7659 - val_loss: 27075.3271\n",
      "Epoch 147/1000\n",
      "1137/1137 [==============================] - 0s 290us/step - loss: 22198.3718 - val_loss: 27700.0835\n",
      "Epoch 148/1000\n",
      "1137/1137 [==============================] - 0s 301us/step - loss: 22115.8703 - val_loss: 27084.8882\n",
      "Epoch 149/1000\n",
      "1137/1137 [==============================] - 0s 302us/step - loss: 22006.7029 - val_loss: 27133.5526\n",
      "Epoch 150/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: 22392.1827 - val_loss: 28211.0934\n",
      "Epoch 151/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: 22185.2841 - val_loss: 27332.5628\n",
      "Epoch 152/1000\n",
      "1137/1137 [==============================] - 0s 289us/step - loss: 22013.0260 - val_loss: 27408.0871\n",
      "Epoch 153/1000\n",
      "1137/1137 [==============================] - 0s 340us/step - loss: 22008.2142 - val_loss: 27624.4662\n",
      "Epoch 154/1000\n",
      "1137/1137 [==============================] - 0s 329us/step - loss: 22092.0947 - val_loss: 26794.0990\n",
      "Epoch 155/1000\n",
      "1137/1137 [==============================] - 0s 301us/step - loss: 22119.0999 - val_loss: 27971.1482\n",
      "Epoch 156/1000\n",
      "1137/1137 [==============================] - 0s 352us/step - loss: 22127.6823 - val_loss: 26951.0460\n",
      "Epoch 157/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: 21971.4788 - val_loss: 27960.2701\n",
      "Epoch 158/1000\n",
      "1137/1137 [==============================] - 0s 318us/step - loss: 22037.1832 - val_loss: 27041.3503\n",
      "Epoch 159/1000\n",
      "1137/1137 [==============================] - 0s 359us/step - loss: 22104.9817 - val_loss: 27450.8880\n",
      "Epoch 160/1000\n",
      "1137/1137 [==============================] - 0s 317us/step - loss: 22116.9143 - val_loss: 26751.1424\n",
      "Epoch 161/1000\n",
      "1137/1137 [==============================] - 0s 324us/step - loss: 21979.9238 - val_loss: 27025.1432\n",
      "Epoch 162/1000\n",
      "1137/1137 [==============================] - 0s 341us/step - loss: 21860.2212 - val_loss: 27196.1960\n",
      "Epoch 163/1000\n",
      "1137/1137 [==============================] - 0s 374us/step - loss: 21871.1626 - val_loss: 27053.3224\n",
      "Epoch 164/1000\n",
      "1137/1137 [==============================] - 0s 311us/step - loss: 21888.6905 - val_loss: 27160.7300\n",
      "Epoch 165/1000\n",
      "1137/1137 [==============================] - 0s 318us/step - loss: 21942.3383 - val_loss: 27107.7952\n",
      "Epoch 166/1000\n",
      "1137/1137 [==============================] - 0s 280us/step - loss: 21946.7746 - val_loss: 27190.8930\n",
      "Epoch 167/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 22109.4564 - val_loss: 27543.9874\n",
      "Epoch 168/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: 21776.6603 - val_loss: 26571.4692\n",
      "Epoch 169/1000\n",
      "1137/1137 [==============================] - 0s 282us/step - loss: 21688.3217 - val_loss: 26932.1403\n",
      "Epoch 170/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: 22047.6200 - val_loss: 27237.3318\n",
      "Epoch 171/1000\n",
      "1137/1137 [==============================] - 0s 316us/step - loss: 21842.2985 - val_loss: 26884.2905\n",
      "Epoch 172/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: 22016.4182 - val_loss: 27297.8906\n",
      "Epoch 173/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: 21686.1645 - val_loss: 27504.0382\n",
      "Epoch 174/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 22396.1011 - val_loss: 27376.1133\n",
      "Epoch 175/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 21631.4536 - val_loss: 28006.7618\n",
      "Epoch 176/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: 21762.8274 - val_loss: 27038.4563\n",
      "Epoch 177/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 21365.8411 - val_loss: 26836.8059\n",
      "Epoch 178/1000\n",
      "1137/1137 [==============================] - 0s 331us/step - loss: 21340.9424 - val_loss: 26812.6321\n",
      "Epoch 179/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: 21818.7632 - val_loss: 26477.8635\n",
      "Epoch 180/1000\n",
      "1137/1137 [==============================] - 0s 280us/step - loss: 21712.8722 - val_loss: 26448.3132\n",
      "Epoch 181/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: 21519.7633 - val_loss: 26413.3955\n",
      "Epoch 182/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 21797.0047 - val_loss: 27450.9917\n",
      "Epoch 183/1000\n",
      "1137/1137 [==============================] - 0s 287us/step - loss: 21673.9661 - val_loss: 26658.0908\n",
      "Epoch 184/1000\n",
      "1137/1137 [==============================] - 0s 329us/step - loss: 21330.2769 - val_loss: 26323.7559\n",
      "Epoch 185/1000\n",
      "1137/1137 [==============================] - 0s 282us/step - loss: 21375.3477 - val_loss: 26380.7407\n",
      "Epoch 186/1000\n",
      "1137/1137 [==============================] - 0s 282us/step - loss: 21551.2254 - val_loss: 26335.6444\n",
      "Epoch 187/1000\n",
      "1137/1137 [==============================] - 0s 303us/step - loss: 21437.4350 - val_loss: 27291.2545\n",
      "Epoch 188/1000\n",
      "1137/1137 [==============================] - 0s 286us/step - loss: 21433.2806 - val_loss: 26304.9488\n",
      "Epoch 189/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 21194.2794 - val_loss: 28072.2065\n",
      "Epoch 190/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 21350.9490 - val_loss: 26452.9111\n",
      "Epoch 191/1000\n",
      "1137/1137 [==============================] - 0s 314us/step - loss: 21876.8510 - val_loss: 27482.9835\n",
      "Epoch 192/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: 21170.8871 - val_loss: 27275.5500\n",
      "Epoch 193/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 21044.3909 - val_loss: 26576.2971\n",
      "Epoch 194/1000\n",
      "1137/1137 [==============================] - 0s 294us/step - loss: 21521.1246 - val_loss: 26390.2877\n",
      "Epoch 195/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: 21287.9403 - val_loss: 26456.9200\n",
      "Epoch 196/1000\n",
      "1137/1137 [==============================] - 0s 294us/step - loss: 21331.7579 - val_loss: 26291.9794\n",
      "Epoch 197/1000\n",
      "1137/1137 [==============================] - 0s 309us/step - loss: 21108.2831 - val_loss: 26080.8088\n",
      "Epoch 198/1000\n",
      "1137/1137 [==============================] - 0s 276us/step - loss: 21259.1135 - val_loss: 27164.7048\n",
      "Epoch 199/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: 21320.6090 - val_loss: 26148.4369\n",
      "Epoch 200/1000\n",
      "1137/1137 [==============================] - 0s 282us/step - loss: 20870.9058 - val_loss: 26033.1742\n",
      "Epoch 201/1000\n",
      "1137/1137 [==============================] - 0s 295us/step - loss: 21106.0129 - val_loss: 26335.8425\n",
      "Epoch 202/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 21247.1659 - val_loss: 26557.7943\n",
      "Epoch 203/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 20838.4905 - val_loss: 26176.7606\n",
      "Epoch 204/1000\n",
      "1137/1137 [==============================] - 0s 297us/step - loss: 20909.6673 - val_loss: 26200.3323\n",
      "Epoch 205/1000\n",
      "1137/1137 [==============================] - 0s 286us/step - loss: 21192.1858 - val_loss: 26376.6422\n",
      "Epoch 206/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: 20994.5744 - val_loss: 26909.1184\n",
      "Epoch 207/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: 20905.8978 - val_loss: 26334.9233\n",
      "Epoch 208/1000\n",
      "1137/1137 [==============================] - 0s 286us/step - loss: 20965.5589 - val_loss: 27516.2122\n",
      "Epoch 209/1000\n",
      "1137/1137 [==============================] - 0s 281us/step - loss: 20896.6729 - val_loss: 26932.8609\n",
      "Epoch 210/1000\n",
      "1137/1137 [==============================] - 0s 293us/step - loss: 21422.2234 - val_loss: 25957.3330\n",
      "Epoch 211/1000\n",
      "1137/1137 [==============================] - 0s 309us/step - loss: 20655.6708 - val_loss: 26785.6242\n",
      "Epoch 212/1000\n",
      "1137/1137 [==============================] - 0s 255us/step - loss: 21016.7109 - val_loss: 25896.7663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/1000\n",
      "1137/1137 [==============================] - 0s 305us/step - loss: 20832.9412 - val_loss: 26450.6436\n",
      "Epoch 214/1000\n",
      "1137/1137 [==============================] - 0s 294us/step - loss: 20875.7785 - val_loss: 25887.4409\n",
      "Epoch 215/1000\n",
      "1137/1137 [==============================] - 0s 276us/step - loss: 21156.6731 - val_loss: 27453.7689\n",
      "Epoch 216/1000\n",
      "1137/1137 [==============================] - 0s 260us/step - loss: 20802.4481 - val_loss: 26875.7976\n",
      "Epoch 217/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 20747.8448 - val_loss: 26140.7332\n",
      "Epoch 218/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: 20455.2238 - val_loss: 26081.5551\n",
      "Epoch 219/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: 21110.9583 - val_loss: 27920.2730\n",
      "Epoch 220/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: 20293.5117 - val_loss: 25987.5138\n",
      "Epoch 221/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: 20704.6285 - val_loss: 25689.6103\n",
      "Epoch 222/1000\n",
      "1137/1137 [==============================] - 0s 273us/step - loss: 20368.0827 - val_loss: 25686.9348\n",
      "Epoch 223/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: 20580.3143 - val_loss: 25873.4816\n",
      "Epoch 224/1000\n",
      "1137/1137 [==============================] - 0s 276us/step - loss: 20491.5238 - val_loss: 26689.1100\n",
      "Epoch 225/1000\n",
      "1137/1137 [==============================] - 0s 275us/step - loss: 20527.2289 - val_loss: 26658.2882\n",
      "Epoch 226/1000\n",
      "1137/1137 [==============================] - 0s 261us/step - loss: 20310.7753 - val_loss: 25588.3415\n",
      "Epoch 227/1000\n",
      "1137/1137 [==============================] - 0s 276us/step - loss: 20345.2791 - val_loss: 25839.8049\n",
      "Epoch 228/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: 20425.7082 - val_loss: 25616.6541\n",
      "Epoch 229/1000\n",
      "1137/1137 [==============================] - 0s 302us/step - loss: 20258.0403 - val_loss: 26581.5452\n",
      "Epoch 230/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 20202.5684 - val_loss: 26553.6157\n",
      "Epoch 231/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 20223.1680 - val_loss: 26074.2829\n",
      "Epoch 232/1000\n",
      "1137/1137 [==============================] - 0s 287us/step - loss: 20158.3420 - val_loss: 25871.9417\n",
      "Epoch 233/1000\n",
      "1137/1137 [==============================] - 0s 273us/step - loss: 20249.1977 - val_loss: 25485.9109\n",
      "Epoch 234/1000\n",
      "1137/1137 [==============================] - 0s 269us/step - loss: 20556.5547 - val_loss: 25471.8393\n",
      "Epoch 235/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 20522.6174 - val_loss: 25419.5608\n",
      "Epoch 236/1000\n",
      "1137/1137 [==============================] - 0s 280us/step - loss: 19921.5447 - val_loss: 25616.2572\n",
      "Epoch 237/1000\n",
      "1137/1137 [==============================] - 0s 286us/step - loss: 20340.7033 - val_loss: 25539.8304\n",
      "Epoch 238/1000\n",
      "1137/1137 [==============================] - 0s 311us/step - loss: 20364.3115 - val_loss: 25633.3825\n",
      "Epoch 239/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 20014.4258 - val_loss: 25841.7786\n",
      "Epoch 240/1000\n",
      "1137/1137 [==============================] - 0s 319us/step - loss: 20063.1361 - val_loss: 25345.1237\n",
      "Epoch 241/1000\n",
      "1137/1137 [==============================] - 0s 355us/step - loss: 20214.5941 - val_loss: 26327.1688\n",
      "Epoch 242/1000\n",
      "1137/1137 [==============================] - 0s 380us/step - loss: 19969.3385 - val_loss: 26580.6306\n",
      "Epoch 243/1000\n",
      "1137/1137 [==============================] - 0s 356us/step - loss: 19925.0314 - val_loss: 25303.0614\n",
      "Epoch 244/1000\n",
      "1137/1137 [==============================] - 0s 391us/step - loss: 20565.7946 - val_loss: 25402.6384\n",
      "Epoch 245/1000\n",
      "1137/1137 [==============================] - 0s 350us/step - loss: 20318.4011 - val_loss: 25553.7546\n",
      "Epoch 246/1000\n",
      "1137/1137 [==============================] - 0s 334us/step - loss: 20004.8439 - val_loss: 25409.6249\n",
      "Epoch 247/1000\n",
      "1137/1137 [==============================] - 0s 345us/step - loss: 20529.5861 - val_loss: 25338.0327\n",
      "Epoch 248/1000\n",
      "1137/1137 [==============================] - 0s 319us/step - loss: 19957.6403 - val_loss: 25378.8187\n",
      "Epoch 249/1000\n",
      "1137/1137 [==============================] - 0s 295us/step - loss: 19841.3640 - val_loss: 25275.3193\n",
      "Epoch 250/1000\n",
      "1137/1137 [==============================] - 0s 329us/step - loss: 20140.0281 - val_loss: 25443.3300\n",
      "Epoch 251/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: 19733.9718 - val_loss: 25640.4372\n",
      "Epoch 252/1000\n",
      "1137/1137 [==============================] - 0s 324us/step - loss: 19968.8483 - val_loss: 25028.8755\n",
      "Epoch 253/1000\n",
      "1137/1137 [==============================] - 0s 352us/step - loss: 19647.8563 - val_loss: 26086.2817\n",
      "Epoch 254/1000\n",
      "1137/1137 [==============================] - 0s 296us/step - loss: 19574.2333 - val_loss: 26348.1321\n",
      "Epoch 255/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 19882.0521 - val_loss: 25034.3893\n",
      "Epoch 256/1000\n",
      "1137/1137 [==============================] - 0s 287us/step - loss: 19637.9664 - val_loss: 24948.2714\n",
      "Epoch 257/1000\n",
      "1137/1137 [==============================] - 0s 249us/step - loss: 19581.4872 - val_loss: 25165.2692\n",
      "Epoch 258/1000\n",
      "1137/1137 [==============================] - 0s 266us/step - loss: 19397.8600 - val_loss: 24996.1641\n",
      "Epoch 259/1000\n",
      "1137/1137 [==============================] - 0s 254us/step - loss: 19331.7068 - val_loss: 24839.5902\n",
      "Epoch 260/1000\n",
      "1137/1137 [==============================] - 0s 319us/step - loss: 19489.9025 - val_loss: 25382.8557\n",
      "Epoch 261/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 19468.1242 - val_loss: 25574.0061\n",
      "Epoch 262/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 19552.6407 - val_loss: 26277.2418\n",
      "Epoch 263/1000\n",
      "1137/1137 [==============================] - 0s 297us/step - loss: 19921.4856 - val_loss: 25536.9676\n",
      "Epoch 264/1000\n",
      "1137/1137 [==============================] - 0s 262us/step - loss: 19393.8930 - val_loss: 24890.9361\n",
      "Epoch 265/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 19627.0041 - val_loss: 26238.5955\n",
      "Epoch 266/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 19423.6934 - val_loss: 25771.9051\n",
      "Epoch 267/1000\n",
      "1137/1137 [==============================] - 0s 297us/step - loss: 19495.4946 - val_loss: 24744.8538\n",
      "Epoch 268/1000\n",
      "1137/1137 [==============================] - 0s 273us/step - loss: 19356.7437 - val_loss: 24684.1976\n",
      "Epoch 269/1000\n",
      "1137/1137 [==============================] - 0s 249us/step - loss: 19500.6780 - val_loss: 25190.2943\n",
      "Epoch 270/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 19168.5718 - val_loss: 24686.7267\n",
      "Epoch 271/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 19342.7219 - val_loss: 24944.9544\n",
      "Epoch 272/1000\n",
      "1137/1137 [==============================] - 0s 247us/step - loss: 19163.4133 - val_loss: 27794.6947\n",
      "Epoch 273/1000\n",
      "1137/1137 [==============================] - 0s 280us/step - loss: 19596.7164 - val_loss: 24869.7142\n",
      "Epoch 274/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 19161.2677 - val_loss: 24400.6564\n",
      "Epoch 275/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 19209.1849 - val_loss: 25393.4008\n",
      "Epoch 276/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 19571.3809 - val_loss: 24842.7208\n",
      "Epoch 277/1000\n",
      "1137/1137 [==============================] - 0s 289us/step - loss: 19210.8071 - val_loss: 26125.3682\n",
      "Epoch 278/1000\n",
      "1137/1137 [==============================] - 0s 245us/step - loss: 19307.3864 - val_loss: 24366.8130\n",
      "Epoch 279/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 18740.7066 - val_loss: 24563.6557\n",
      "Epoch 280/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: 19023.9274 - val_loss: 26191.0450\n",
      "Epoch 281/1000\n",
      "1137/1137 [==============================] - ETA: 0s - loss: 19315.119 - 0s 287us/step - loss: 19430.7229 - val_loss: 24823.6679\n",
      "Epoch 282/1000\n",
      "1137/1137 [==============================] - 0s 324us/step - loss: 19001.5811 - val_loss: 24663.1538\n",
      "Epoch 283/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 264us/step - loss: 18961.5449 - val_loss: 24900.8538\n",
      "Epoch 284/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 18950.4144 - val_loss: 24415.1975\n",
      "Epoch 285/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 18617.9745 - val_loss: 24736.2241\n",
      "Epoch 286/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 18928.2506 - val_loss: 24106.7644\n",
      "Epoch 287/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 19286.0049 - val_loss: 24634.5536\n",
      "Epoch 288/1000\n",
      "1137/1137 [==============================] - 0s 244us/step - loss: 18964.4361 - val_loss: 24621.4136\n",
      "Epoch 289/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: 18813.6496 - val_loss: 24731.5807\n",
      "Epoch 290/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 18962.1864 - val_loss: 25281.0034\n",
      "Epoch 291/1000\n",
      "1137/1137 [==============================] - 0s 283us/step - loss: 18579.0774 - val_loss: 24610.0812\n",
      "Epoch 292/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: 18735.0929 - val_loss: 24645.8540\n",
      "Epoch 293/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 18686.6038 - val_loss: 24561.8070\n",
      "Epoch 294/1000\n",
      "1137/1137 [==============================] - 0s 303us/step - loss: 18804.2254 - val_loss: 23940.0747\n",
      "Epoch 295/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: 18705.9665 - val_loss: 24187.4774\n",
      "Epoch 296/1000\n",
      "1137/1137 [==============================] - 0s 274us/step - loss: 19000.0467 - val_loss: 24076.7066\n",
      "Epoch 297/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 18313.1801 - val_loss: 23920.4523\n",
      "Epoch 298/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 18686.2473 - val_loss: 24215.7604\n",
      "Epoch 299/1000\n",
      "1137/1137 [==============================] - 0s 283us/step - loss: 18301.9453 - val_loss: 24733.6200\n",
      "Epoch 300/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 18682.5216 - val_loss: 24096.2945\n",
      "Epoch 301/1000\n",
      "1137/1137 [==============================] - 0s 287us/step - loss: 18460.3986 - val_loss: 24029.6811\n",
      "Epoch 302/1000\n",
      "1137/1137 [==============================] - 0s 250us/step - loss: 18436.4231 - val_loss: 24735.8167\n",
      "Epoch 303/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 18360.3131 - val_loss: 23847.5573\n",
      "Epoch 304/1000\n",
      "1137/1137 [==============================] - 0s 260us/step - loss: 18236.3950 - val_loss: 24910.4028\n",
      "Epoch 305/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 18111.6987 - val_loss: 23890.2007\n",
      "Epoch 306/1000\n",
      "1137/1137 [==============================] - 0s 275us/step - loss: 18170.5932 - val_loss: 24056.5116\n",
      "Epoch 307/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 18279.8777 - val_loss: 25290.0797\n",
      "Epoch 308/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 18609.2472 - val_loss: 23842.2221\n",
      "Epoch 309/1000\n",
      "1137/1137 [==============================] - 0s 263us/step - loss: 18938.4709 - val_loss: 23769.5211\n",
      "Epoch 310/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: 18115.7574 - val_loss: 23447.7384\n",
      "Epoch 311/1000\n",
      "1137/1137 [==============================] - 0s 263us/step - loss: 18380.3573 - val_loss: 23777.7417\n",
      "Epoch 312/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 18210.4470 - val_loss: 23852.4746\n",
      "Epoch 313/1000\n",
      "1137/1137 [==============================] - 0s 274us/step - loss: 18354.9922 - val_loss: 23600.7315\n",
      "Epoch 314/1000\n",
      "1137/1137 [==============================] - 0s 256us/step - loss: 18286.0094 - val_loss: 24162.2280\n",
      "Epoch 315/1000\n",
      "1137/1137 [==============================] - 0s 260us/step - loss: 18126.7877 - val_loss: 23579.5099\n",
      "Epoch 316/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 18290.3523 - val_loss: 23243.7376\n",
      "Epoch 317/1000\n",
      "1137/1137 [==============================] - 0s 269us/step - loss: 17847.9686 - val_loss: 23400.6274\n",
      "Epoch 318/1000\n",
      "1137/1137 [==============================] - 0s 263us/step - loss: 18301.2756 - val_loss: 23472.6180\n",
      "Epoch 319/1000\n",
      "1137/1137 [==============================] - 0s 294us/step - loss: 18234.6083 - val_loss: 23570.7820\n",
      "Epoch 320/1000\n",
      "1137/1137 [==============================] - 0s 250us/step - loss: 18119.2618 - val_loss: 23764.7290\n",
      "Epoch 321/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 18538.1104 - val_loss: 25204.0596\n",
      "Epoch 322/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 17938.2503 - val_loss: 23133.8545\n",
      "Epoch 323/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 18240.7906 - val_loss: 23777.2957\n",
      "Epoch 324/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 18215.1104 - val_loss: 23689.9239\n",
      "Epoch 325/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 18134.5508 - val_loss: 23061.9314\n",
      "Epoch 326/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 17803.5370 - val_loss: 25102.0418\n",
      "Epoch 327/1000\n",
      "1137/1137 [==============================] - 0s 256us/step - loss: 18080.4830 - val_loss: 23274.1210\n",
      "Epoch 328/1000\n",
      "1137/1137 [==============================] - 0s 256us/step - loss: 18007.9726 - val_loss: 23802.4270\n",
      "Epoch 329/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 18205.7875 - val_loss: 25231.9275\n",
      "Epoch 330/1000\n",
      "1137/1137 [==============================] - 0s 283us/step - loss: 18129.1544 - val_loss: 23187.1128\n",
      "Epoch 331/1000\n",
      "1137/1137 [==============================] - 0s 406us/step - loss: 17962.6773 - val_loss: 23420.4759\n",
      "Epoch 332/1000\n",
      "1137/1137 [==============================] - 1s 443us/step - loss: 18032.8170 - val_loss: 23491.8645\n",
      "Epoch 333/1000\n",
      "1137/1137 [==============================] - 0s 364us/step - loss: 17999.7795 - val_loss: 23063.2048\n",
      "Epoch 334/1000\n",
      "1137/1137 [==============================] - 0s 290us/step - loss: 17663.3333 - val_loss: 23121.3672\n",
      "Epoch 335/1000\n",
      "1137/1137 [==============================] - 0s 320us/step - loss: 17612.5977 - val_loss: 23126.9215\n",
      "Epoch 336/1000\n",
      "1137/1137 [==============================] - 0s 294us/step - loss: 17803.5729 - val_loss: 24441.1867\n",
      "Epoch 337/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: 18369.4500 - val_loss: 22859.0131\n",
      "Epoch 338/1000\n",
      "1137/1137 [==============================] - 0s 308us/step - loss: 17671.7840 - val_loss: 24848.5027\n",
      "Epoch 339/1000\n",
      "1137/1137 [==============================] - 0s 330us/step - loss: 17752.3133 - val_loss: 23022.6446\n",
      "Epoch 340/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 17437.8669 - val_loss: 22872.3827\n",
      "Epoch 341/1000\n",
      "1137/1137 [==============================] - 0s 363us/step - loss: 18090.4032 - val_loss: 23331.9263\n",
      "Epoch 342/1000\n",
      "1137/1137 [==============================] - 0s 311us/step - loss: 17787.1776 - val_loss: 23217.3467\n",
      "Epoch 343/1000\n",
      "1137/1137 [==============================] - 0s 337us/step - loss: 17651.6450 - val_loss: 25764.1694\n",
      "Epoch 344/1000\n",
      "1137/1137 [==============================] - 0s 362us/step - loss: 17619.6411 - val_loss: 24122.5069\n",
      "Epoch 345/1000\n",
      "1137/1137 [==============================] - 0s 301us/step - loss: 17676.9714 - val_loss: 22656.4585\n",
      "Epoch 346/1000\n",
      "1137/1137 [==============================] - 0s 307us/step - loss: 17471.5898 - val_loss: 23457.6866\n",
      "Epoch 347/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: 17460.4748 - val_loss: 23076.3990\n",
      "Epoch 348/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: 17642.0662 - val_loss: 22729.7931\n",
      "Epoch 349/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: 17376.4620 - val_loss: 23718.1703\n",
      "Epoch 350/1000\n",
      "1137/1137 [==============================] - 0s 275us/step - loss: 17636.0624 - val_loss: 23058.3320\n",
      "Epoch 351/1000\n",
      "1137/1137 [==============================] - 0s 289us/step - loss: 18022.9202 - val_loss: 22741.5657\n",
      "Epoch 352/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: 17305.1151 - val_loss: 23099.1075\n",
      "Epoch 353/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 17534.1659 - val_loss: 22981.2318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 17865.4538 - val_loss: 22828.7614\n",
      "Epoch 355/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 17866.2541 - val_loss: 23127.4882\n",
      "Epoch 356/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 17554.5915 - val_loss: 23705.2172\n",
      "Epoch 357/1000\n",
      "1137/1137 [==============================] - 0s 290us/step - loss: 17523.3937 - val_loss: 22404.3800\n",
      "Epoch 358/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 18004.2261 - val_loss: 22707.5479\n",
      "Epoch 359/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 17432.3548 - val_loss: 22503.6257\n",
      "Epoch 360/1000\n",
      "1137/1137 [==============================] - 0s 256us/step - loss: 17656.4482 - val_loss: 23612.3986\n",
      "Epoch 361/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 17328.5418 - val_loss: 22449.6717\n",
      "Epoch 362/1000\n",
      "1137/1137 [==============================] - 0s 276us/step - loss: 17417.7627 - val_loss: 23489.3689\n",
      "Epoch 363/1000\n",
      "1137/1137 [==============================] - 0s 269us/step - loss: 17774.9563 - val_loss: 22433.2939\n",
      "Epoch 364/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 17422.6336 - val_loss: 23674.9016\n",
      "Epoch 365/1000\n",
      "1137/1137 [==============================] - 0s 282us/step - loss: 17549.4995 - val_loss: 22169.0277\n",
      "Epoch 366/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 17272.7936 - val_loss: 22029.5315\n",
      "Epoch 367/1000\n",
      "1137/1137 [==============================] - 0s 274us/step - loss: 17553.4193 - val_loss: 22732.2639\n",
      "Epoch 368/1000\n",
      "1137/1137 [==============================] - 0s 281us/step - loss: 17341.5914 - val_loss: 25351.1052\n",
      "Epoch 369/1000\n",
      "1137/1137 [==============================] - 0s 280us/step - loss: 17341.2223 - val_loss: 23101.0268\n",
      "Epoch 370/1000\n",
      "1137/1137 [==============================] - 0s 288us/step - loss: 17316.3813 - val_loss: 22319.0868\n",
      "Epoch 371/1000\n",
      "1137/1137 [==============================] - 0s 263us/step - loss: 17511.4789 - val_loss: 22160.2557\n",
      "Epoch 372/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: 17403.9044 - val_loss: 22175.8661\n",
      "Epoch 373/1000\n",
      "1137/1137 [==============================] - 0s 260us/step - loss: 17570.9711 - val_loss: 22362.6148\n",
      "Epoch 374/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: 16857.3787 - val_loss: 22092.3940\n",
      "Epoch 375/1000\n",
      "1137/1137 [==============================] - 0s 273us/step - loss: 17612.1175 - val_loss: 22309.4257\n",
      "Epoch 376/1000\n",
      "1137/1137 [==============================] - 0s 283us/step - loss: 17344.7564 - val_loss: 22311.3352\n",
      "Epoch 377/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: 18128.8421 - val_loss: 22526.7433\n",
      "Epoch 378/1000\n",
      "1137/1137 [==============================] - 0s 255us/step - loss: 17539.0362 - val_loss: 23255.8049\n",
      "Epoch 379/1000\n",
      "1137/1137 [==============================] - 0s 281us/step - loss: 17218.3372 - val_loss: 23216.6593\n",
      "Epoch 380/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 17437.3302 - val_loss: 22432.0628\n",
      "Epoch 381/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 17375.4006 - val_loss: 23336.5306\n",
      "Epoch 382/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 17296.4614 - val_loss: 21990.5454\n",
      "Epoch 383/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: 17442.3694 - val_loss: 21990.8860\n",
      "Epoch 384/1000\n",
      "1137/1137 [==============================] - 0s 254us/step - loss: 17448.8678 - val_loss: 22090.6471\n",
      "Epoch 385/1000\n",
      "1137/1137 [==============================] - 0s 268us/step - loss: 16873.6304 - val_loss: 22418.5813\n",
      "Epoch 386/1000\n",
      "1137/1137 [==============================] - 0s 287us/step - loss: 16786.7229 - val_loss: 21824.9182\n",
      "Epoch 387/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: 17217.3300 - val_loss: 22190.8140\n",
      "Epoch 388/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: 17092.8665 - val_loss: 21944.2430\n",
      "Epoch 389/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 17227.2708 - val_loss: 21902.1806\n",
      "Epoch 390/1000\n",
      "1137/1137 [==============================] - 0s 294us/step - loss: 16904.3953 - val_loss: 25687.8239\n",
      "Epoch 391/1000\n",
      "1137/1137 [==============================] - 0s 263us/step - loss: 17578.6533 - val_loss: 22168.5421\n",
      "Epoch 392/1000\n",
      "1137/1137 [==============================] - 0s 255us/step - loss: 17153.5859 - val_loss: 22245.3926\n",
      "Epoch 393/1000\n",
      "1137/1137 [==============================] - 0s 300us/step - loss: 17272.9071 - val_loss: 21648.3162\n",
      "Epoch 394/1000\n",
      "1137/1137 [==============================] - 0s 255us/step - loss: 16905.6037 - val_loss: 21968.2022\n",
      "Epoch 395/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 17316.3408 - val_loss: 21927.9019\n",
      "Epoch 396/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 16805.3827 - val_loss: 22098.2090\n",
      "Epoch 397/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: 17293.2149 - val_loss: 21992.2260\n",
      "Epoch 398/1000\n",
      "1137/1137 [==============================] - 0s 268us/step - loss: 16988.3923 - val_loss: 21929.6433\n",
      "Epoch 399/1000\n",
      "1137/1137 [==============================] - 0s 276us/step - loss: 16911.5834 - val_loss: 24196.2754\n",
      "Epoch 400/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: 16974.3421 - val_loss: 21732.4635\n",
      "Epoch 401/1000\n",
      "1137/1137 [==============================] - 0s 253us/step - loss: 16768.5635 - val_loss: 21998.2167\n",
      "Epoch 402/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 16832.8287 - val_loss: 23726.8259\n",
      "Epoch 403/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 16963.7879 - val_loss: 21647.2923\n",
      "Epoch 404/1000\n",
      "1137/1137 [==============================] - 0s 323us/step - loss: 16907.2654 - val_loss: 21623.8445\n",
      "Epoch 405/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: 17405.8009 - val_loss: 21859.8655\n",
      "Epoch 406/1000\n",
      "1137/1137 [==============================] - 0s 276us/step - loss: 16712.7301 - val_loss: 21590.5916\n",
      "Epoch 407/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 16800.4939 - val_loss: 21952.2782\n",
      "Epoch 408/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 16533.8380 - val_loss: 22221.9801\n",
      "Epoch 409/1000\n",
      "1137/1137 [==============================] - 0s 276us/step - loss: 17001.9065 - val_loss: 22666.2479\n",
      "Epoch 410/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 17042.4048 - val_loss: 21484.0156\n",
      "Epoch 411/1000\n",
      "1137/1137 [==============================] - 0s 299us/step - loss: 16950.1648 - val_loss: 21586.8742\n",
      "Epoch 412/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 16735.2762 - val_loss: 21962.8770\n",
      "Epoch 413/1000\n",
      "1137/1137 [==============================] - 0s 254us/step - loss: 16989.0835 - val_loss: 21852.8040\n",
      "Epoch 414/1000\n",
      "1137/1137 [==============================] - 0s 293us/step - loss: 16764.1638 - val_loss: 21504.4778\n",
      "Epoch 415/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 16711.6239 - val_loss: 22009.0471\n",
      "Epoch 416/1000\n",
      "1137/1137 [==============================] - 0s 255us/step - loss: 16587.4054 - val_loss: 21833.1378\n",
      "Epoch 417/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: 16432.2944 - val_loss: 21909.3013\n",
      "Epoch 418/1000\n",
      "1137/1137 [==============================] - 0s 337us/step - loss: 16656.6037 - val_loss: 21834.8425\n",
      "Epoch 419/1000\n",
      "1137/1137 [==============================] - 0s 253us/step - loss: 16724.3664 - val_loss: 22411.7097\n",
      "Epoch 420/1000\n",
      "1137/1137 [==============================] - 0s 274us/step - loss: 17469.1267 - val_loss: 21580.4578\n",
      "Epoch 421/1000\n",
      "1137/1137 [==============================] - 0s 332us/step - loss: 16896.2112 - val_loss: 21500.2029\n",
      "Epoch 422/1000\n",
      "1137/1137 [==============================] - 0s 246us/step - loss: 16909.0629 - val_loss: 21376.2840\n",
      "Epoch 423/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 16747.4470 - val_loss: 21548.5594\n",
      "Epoch 424/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 272us/step - loss: 16403.2948 - val_loss: 22074.6623\n",
      "Epoch 425/1000\n",
      "1137/1137 [==============================] - 0s 283us/step - loss: 16748.4792 - val_loss: 21408.3706\n",
      "Epoch 426/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 16584.5408 - val_loss: 21525.6255\n",
      "Epoch 427/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 16607.8648 - val_loss: 21721.9572\n",
      "Epoch 428/1000\n",
      "1137/1137 [==============================] - 0s 324us/step - loss: 17365.3688 - val_loss: 22740.3293\n",
      "Epoch 429/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: 16356.4108 - val_loss: 21634.5524\n",
      "Epoch 430/1000\n",
      "1137/1137 [==============================] - 0s 289us/step - loss: 16505.1588 - val_loss: 21261.5493\n",
      "Epoch 431/1000\n",
      "1137/1137 [==============================] - 0s 336us/step - loss: 16492.8458 - val_loss: 21386.8924\n",
      "Epoch 432/1000\n",
      "1137/1137 [==============================] - 0s 273us/step - loss: 16957.5028 - val_loss: 21922.9476\n",
      "Epoch 433/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: 16363.3839 - val_loss: 21627.9521\n",
      "Epoch 434/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: 16354.2169 - val_loss: 21879.6920\n",
      "Epoch 435/1000\n",
      "1137/1137 [==============================] - 0s 305us/step - loss: 16367.3198 - val_loss: 21356.4274\n",
      "Epoch 436/1000\n",
      "1137/1137 [==============================] - 0s 316us/step - loss: 16183.1535 - val_loss: 23869.4595\n",
      "Epoch 437/1000\n",
      "1137/1137 [==============================] - 0s 296us/step - loss: 16667.2967 - val_loss: 21491.7406\n",
      "Epoch 438/1000\n",
      "1137/1137 [==============================] - 0s 349us/step - loss: 16691.6854 - val_loss: 23399.3893\n",
      "Epoch 439/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: 16405.8126 - val_loss: 21131.6317\n",
      "Epoch 440/1000\n",
      "1137/1137 [==============================] - 0s 253us/step - loss: 16559.8593 - val_loss: 21314.4179\n",
      "Epoch 441/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 16509.8689 - val_loss: 21456.2132\n",
      "Epoch 442/1000\n",
      "1137/1137 [==============================] - 0s 263us/step - loss: 16348.2803 - val_loss: 21736.4391\n",
      "Epoch 443/1000\n",
      "1137/1137 [==============================] - 0s 266us/step - loss: 16540.5868 - val_loss: 21054.1486\n",
      "Epoch 444/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 15957.2754 - val_loss: 22695.1759\n",
      "Epoch 445/1000\n",
      "1137/1137 [==============================] - 0s 283us/step - loss: 16514.0415 - val_loss: 21779.3273\n",
      "Epoch 446/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 16360.1247 - val_loss: 21454.2729\n",
      "Epoch 447/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 16398.2940 - val_loss: 21052.2542\n",
      "Epoch 448/1000\n",
      "1137/1137 [==============================] - 0s 283us/step - loss: 16480.7106 - val_loss: 21101.8387\n",
      "Epoch 449/1000\n",
      "1137/1137 [==============================] - 0s 250us/step - loss: 16349.1096 - val_loss: 21391.4627\n",
      "Epoch 450/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 16291.1287 - val_loss: 21498.8784\n",
      "Epoch 451/1000\n",
      "1137/1137 [==============================] - 0s 253us/step - loss: 16203.8750 - val_loss: 21397.3606\n",
      "Epoch 452/1000\n",
      "1137/1137 [==============================] - 0s 283us/step - loss: 16330.5813 - val_loss: 23738.6224\n",
      "Epoch 453/1000\n",
      "1137/1137 [==============================] - 0s 250us/step - loss: 16532.7158 - val_loss: 22102.9775\n",
      "Epoch 454/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 16406.9873 - val_loss: 20921.9038\n",
      "Epoch 455/1000\n",
      "1137/1137 [==============================] - 0s 250us/step - loss: 16137.1870 - val_loss: 21005.8835\n",
      "Epoch 456/1000\n",
      "1137/1137 [==============================] - 0s 297us/step - loss: 16042.3474 - val_loss: 21594.8702\n",
      "Epoch 457/1000\n",
      "1137/1137 [==============================] - 0s 263us/step - loss: 16263.9234 - val_loss: 21081.8819\n",
      "Epoch 458/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 16207.6590 - val_loss: 23091.3980\n",
      "Epoch 459/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 16580.5875 - val_loss: 22872.8343\n",
      "Epoch 460/1000\n",
      "1137/1137 [==============================] - 0s 250us/step - loss: 16681.7747 - val_loss: 21144.2620\n",
      "Epoch 461/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 16776.4298 - val_loss: 26596.8667\n",
      "Epoch 462/1000\n",
      "1137/1137 [==============================] - 0s 256us/step - loss: 16662.3898 - val_loss: 20832.9128\n",
      "Epoch 463/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: 16331.0122 - val_loss: 21223.4909\n",
      "Epoch 464/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: 16079.9429 - val_loss: 24074.0927\n",
      "Epoch 465/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 16310.7804 - val_loss: 20725.4152\n",
      "Epoch 466/1000\n",
      "1137/1137 [==============================] - 0s 294us/step - loss: 16283.2966 - val_loss: 21004.2954\n",
      "Epoch 467/1000\n",
      "1137/1137 [==============================] - 0s 245us/step - loss: 16076.4191 - val_loss: 20684.9976\n",
      "Epoch 468/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 16838.4757 - val_loss: 22077.5846\n",
      "Epoch 469/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 16033.5953 - val_loss: 21522.0277\n",
      "Epoch 470/1000\n",
      "1137/1137 [==============================] - 0s 290us/step - loss: 16436.8232 - val_loss: 21584.6032\n",
      "Epoch 471/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 15895.3059 - val_loss: 20969.4454\n",
      "Epoch 472/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 16074.0668 - val_loss: 22596.8309\n",
      "Epoch 473/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 16710.0118 - val_loss: 21732.3943\n",
      "Epoch 474/1000\n",
      "1137/1137 [==============================] - 0s 295us/step - loss: 15968.3347 - val_loss: 20751.7718\n",
      "Epoch 475/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: 16125.0306 - val_loss: 21214.1482\n",
      "Epoch 476/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 16341.8938 - val_loss: 20886.4414\n",
      "Epoch 477/1000\n",
      "1137/1137 [==============================] - 0s 297us/step - loss: 15868.6552 - val_loss: 21024.5446\n",
      "Epoch 478/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 16190.8821 - val_loss: 21587.6195\n",
      "Epoch 479/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 16122.5008 - val_loss: 21805.5295\n",
      "Epoch 480/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 16612.9663 - val_loss: 22447.8336\n",
      "Epoch 481/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 16712.2753 - val_loss: 21447.3343\n",
      "Epoch 482/1000\n",
      "1137/1137 [==============================] - 0s 280us/step - loss: 16601.4689 - val_loss: 22710.4116\n",
      "Epoch 483/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: 16326.8060 - val_loss: 21044.2726\n",
      "Epoch 484/1000\n",
      "1137/1137 [==============================] - 0s 307us/step - loss: 16289.8980 - val_loss: 20777.9871\n",
      "Epoch 485/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 15869.4387 - val_loss: 21065.9006\n",
      "Epoch 486/1000\n",
      "1137/1137 [==============================] - 0s 276us/step - loss: 15766.8310 - val_loss: 20784.9758\n",
      "Epoch 487/1000\n",
      "1137/1137 [==============================] - 0s 299us/step - loss: 16298.1902 - val_loss: 27560.5366\n",
      "Epoch 488/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 16366.9255 - val_loss: 20961.1789\n",
      "Epoch 489/1000\n",
      "1137/1137 [==============================] - 0s 275us/step - loss: 15836.9856 - val_loss: 20599.2213\n",
      "Epoch 490/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: 16143.1657 - val_loss: 21495.7449\n",
      "Epoch 491/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 15993.4461 - val_loss: 20772.9999\n",
      "Epoch 492/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: 16227.5799 - val_loss: 20427.4437\n",
      "Epoch 493/1000\n",
      "1137/1137 [==============================] - 0s 245us/step - loss: 16096.3658 - val_loss: 21439.2368\n",
      "Epoch 494/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: 15928.9445 - val_loss: 20521.2120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/1000\n",
      "1137/1137 [==============================] - 0s 247us/step - loss: 15356.3218 - val_loss: 20647.7625\n",
      "Epoch 496/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 15952.1505 - val_loss: 21134.7640\n",
      "Epoch 497/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 15907.9039 - val_loss: 20497.3782\n",
      "Epoch 498/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: 15551.1339 - val_loss: 21082.6856\n",
      "Epoch 499/1000\n",
      "1137/1137 [==============================] - 0s 249us/step - loss: 16209.8834 - val_loss: 23951.5074\n",
      "Epoch 500/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 16363.6343 - val_loss: 20681.3344\n",
      "Epoch 501/1000\n",
      "1137/1137 [==============================] - 0s 267us/step - loss: 16186.6857 - val_loss: 20483.0563\n",
      "Epoch 502/1000\n",
      "1137/1137 [==============================] - 0s 276us/step - loss: 15646.7321 - val_loss: 20827.6726\n",
      "Epoch 503/1000\n",
      "1137/1137 [==============================] - 0s 254us/step - loss: 15918.2748 - val_loss: 21049.8429\n",
      "Epoch 504/1000\n",
      "1137/1137 [==============================] - 0s 288us/step - loss: 15509.0774 - val_loss: 21540.6102\n",
      "Epoch 505/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: 15825.2889 - val_loss: 20728.9356\n",
      "Epoch 506/1000\n",
      "1137/1137 [==============================] - 0s 241us/step - loss: 15927.7353 - val_loss: 20541.5264\n",
      "Epoch 507/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 15429.9468 - val_loss: 20456.5025\n",
      "Epoch 508/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 15654.7751 - val_loss: 20623.5063\n",
      "Epoch 509/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: 15977.9147 - val_loss: 20893.7238\n",
      "Epoch 510/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 15528.9209 - val_loss: 20554.6858\n",
      "Epoch 511/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: 16029.4092 - val_loss: 21199.0950\n",
      "Epoch 512/1000\n",
      "1137/1137 [==============================] - 0s 283us/step - loss: 15322.6984 - val_loss: 20586.2158\n",
      "Epoch 513/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 16103.2272 - val_loss: 20758.0639\n",
      "Epoch 514/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: 16251.0572 - val_loss: 21439.3711\n",
      "Epoch 515/1000\n",
      "1137/1137 [==============================] - 0s 250us/step - loss: 15619.5887 - val_loss: 20213.6487\n",
      "Epoch 516/1000\n",
      "1137/1137 [==============================] - 0s 288us/step - loss: 15729.1185 - val_loss: 22753.3756\n",
      "Epoch 517/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 16116.0539 - val_loss: 23795.0237\n",
      "Epoch 518/1000\n",
      "1137/1137 [==============================] - 0s 245us/step - loss: 16529.8913 - val_loss: 21282.9633\n",
      "Epoch 519/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 15630.7399 - val_loss: 21077.6137\n",
      "Epoch 520/1000\n",
      "1137/1137 [==============================] - 0s 280us/step - loss: 15580.0916 - val_loss: 20599.5831\n",
      "Epoch 521/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 15642.9012 - val_loss: 20347.8085\n",
      "Epoch 522/1000\n",
      "1137/1137 [==============================] - 0s 266us/step - loss: 15892.7583 - val_loss: 20468.9256\n",
      "Epoch 523/1000\n",
      "1137/1137 [==============================] - 0s 339us/step - loss: 15799.0403 - val_loss: 20411.0028\n",
      "Epoch 524/1000\n",
      "1137/1137 [==============================] - 0s 324us/step - loss: 15657.0632 - val_loss: 20674.8048\n",
      "Epoch 525/1000\n",
      "1137/1137 [==============================] - 0s 331us/step - loss: 15432.4549 - val_loss: 20927.3738\n",
      "Epoch 526/1000\n",
      "1137/1137 [==============================] - 0s 346us/step - loss: 15655.9738 - val_loss: 21134.4263\n",
      "Epoch 527/1000\n",
      "1137/1137 [==============================] - 0s 295us/step - loss: 15756.1036 - val_loss: 21417.8802\n",
      "Epoch 528/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: 15371.2971 - val_loss: 21882.1651\n",
      "Epoch 529/1000\n",
      "1137/1137 [==============================] - 0s 346us/step - loss: 15407.5855 - val_loss: 20248.9707\n",
      "Epoch 530/1000\n",
      "1137/1137 [==============================] - 0s 333us/step - loss: 15617.5040 - val_loss: 21356.7221\n",
      "Epoch 531/1000\n",
      "1137/1137 [==============================] - 0s 282us/step - loss: 15545.7660 - val_loss: 20777.2607\n",
      "Epoch 532/1000\n",
      "1137/1137 [==============================] - 0s 347us/step - loss: 15369.3722 - val_loss: 20287.7780\n",
      "Epoch 533/1000\n",
      "1137/1137 [==============================] - 0s 287us/step - loss: 15651.5855 - val_loss: 23083.0480\n",
      "Epoch 534/1000\n",
      "1137/1137 [==============================] - 0s 286us/step - loss: 15567.6901 - val_loss: 20957.9139\n",
      "Epoch 535/1000\n",
      "1137/1137 [==============================] - 0s 331us/step - loss: 15989.7208 - val_loss: 22100.2387\n",
      "Epoch 536/1000\n",
      "1137/1137 [==============================] - 0s 269us/step - loss: 15886.7210 - val_loss: 20508.3610\n",
      "Epoch 537/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 15525.7141 - val_loss: 25171.4336\n",
      "Epoch 538/1000\n",
      "1137/1137 [==============================] - 0s 274us/step - loss: 15647.2062 - val_loss: 20740.3267\n",
      "Epoch 539/1000\n",
      "1137/1137 [==============================] - 0s 286us/step - loss: 15440.1958 - val_loss: 20290.2677\n",
      "Epoch 540/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 15256.5708 - val_loss: 20432.8238\n",
      "Epoch 541/1000\n",
      "1137/1137 [==============================] - 0s 274us/step - loss: 15191.5475 - val_loss: 20941.2630\n",
      "Epoch 542/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: 15319.8069 - val_loss: 20422.9168\n",
      "Epoch 543/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 15128.4900 - val_loss: 23352.3193\n",
      "Epoch 544/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: 15436.0785 - val_loss: 24694.5816\n",
      "Epoch 545/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: 15209.6666 - val_loss: 20141.4553\n",
      "Epoch 546/1000\n",
      "1137/1137 [==============================] - 0s 299us/step - loss: 15236.8076 - val_loss: 20623.4885\n",
      "Epoch 547/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 15941.2010 - val_loss: 21772.5150\n",
      "Epoch 548/1000\n",
      "1137/1137 [==============================] - 0s 325us/step - loss: 16193.7379 - val_loss: 21338.1171\n",
      "Epoch 549/1000\n",
      "1137/1137 [==============================] - 0s 288us/step - loss: 15265.3576 - val_loss: 20422.5503\n",
      "Epoch 550/1000\n",
      "1137/1137 [==============================] - 0s 266us/step - loss: 15199.6903 - val_loss: 20801.5683\n",
      "Epoch 551/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: 16069.4179 - val_loss: 24678.4897\n",
      "Epoch 552/1000\n",
      "1137/1137 [==============================] - 0s 266us/step - loss: 15709.5997 - val_loss: 20702.9234\n",
      "Epoch 553/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 15142.3818 - val_loss: 20203.0544\n",
      "Epoch 554/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 15163.2275 - val_loss: 20504.8361\n",
      "Epoch 555/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 15372.2442 - val_loss: 23739.5088\n",
      "Epoch 556/1000\n",
      "1137/1137 [==============================] - 0s 308us/step - loss: 14987.9185 - val_loss: 20378.6704\n",
      "Epoch 557/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: 15716.1725 - val_loss: 20623.9490\n",
      "Epoch 558/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 15894.1483 - val_loss: 20412.3391\n",
      "Epoch 559/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 15164.7502 - val_loss: 20138.1391\n",
      "Epoch 560/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 15056.5796 - val_loss: 20498.2831\n",
      "Epoch 561/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 15041.5232 - val_loss: 20709.5986\n",
      "Epoch 562/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 15795.0021 - val_loss: 20148.5080\n",
      "Epoch 563/1000\n",
      "1137/1137 [==============================] - 0s 288us/step - loss: 15171.2171 - val_loss: 20248.0925\n",
      "Epoch 564/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 15242.9589 - val_loss: 20581.8947\n",
      "Epoch 565/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 251us/step - loss: 15177.5822 - val_loss: 21629.3004\n",
      "Epoch 566/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 15289.5971 - val_loss: 21372.1851\n",
      "Epoch 567/1000\n",
      "1137/1137 [==============================] - 0s 306us/step - loss: 15532.6094 - val_loss: 20319.6021\n",
      "Epoch 568/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 15094.4210 - val_loss: 20109.6677\n",
      "Epoch 569/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 15734.3200 - val_loss: 20815.1727\n",
      "Epoch 570/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: 15622.8191 - val_loss: 20223.6029\n",
      "Epoch 571/1000\n",
      "1137/1137 [==============================] - 0s 268us/step - loss: 15099.7307 - val_loss: 20121.5911\n",
      "Epoch 572/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 15267.5021 - val_loss: 20553.6395\n",
      "Epoch 573/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: 15151.1345 - val_loss: 20076.6352\n",
      "Epoch 574/1000\n",
      "1137/1137 [==============================] - 0s 268us/step - loss: 15464.9370 - val_loss: 20304.1660\n",
      "Epoch 575/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 14822.2639 - val_loss: 21617.8407\n",
      "Epoch 576/1000\n",
      "1137/1137 [==============================] - 0s 275us/step - loss: 15191.0926 - val_loss: 21630.4770\n",
      "Epoch 577/1000\n",
      "1137/1137 [==============================] - 0s 282us/step - loss: 15243.3312 - val_loss: 20897.4255\n",
      "Epoch 578/1000\n",
      "1137/1137 [==============================] - 0s 267us/step - loss: 15516.4574 - val_loss: 21767.4527\n",
      "Epoch 579/1000\n",
      "1137/1137 [==============================] - 0s 269us/step - loss: 15004.6918 - val_loss: 20500.9228\n",
      "Epoch 580/1000\n",
      "1137/1137 [==============================] - 0s 280us/step - loss: 14999.3921 - val_loss: 20414.0183\n",
      "Epoch 581/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: 14826.0178 - val_loss: 20549.4419\n",
      "Epoch 582/1000\n",
      "1137/1137 [==============================] - 0s 268us/step - loss: 14822.2459 - val_loss: 23428.8090\n",
      "Epoch 583/1000\n",
      "1137/1137 [==============================] - 0s 262us/step - loss: 15647.4347 - val_loss: 20378.4564\n",
      "Epoch 584/1000\n",
      "1137/1137 [==============================] - 0s 290us/step - loss: 15142.7158 - val_loss: 21586.8366\n",
      "Epoch 585/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 14547.6798 - val_loss: 20113.1044\n",
      "Epoch 586/1000\n",
      "1137/1137 [==============================] - 0s 261us/step - loss: 15122.2746 - val_loss: 20231.3004\n",
      "Epoch 587/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: 14853.7680 - val_loss: 20359.3355\n",
      "Epoch 588/1000\n",
      "1137/1137 [==============================] - 0s 296us/step - loss: 14950.6363 - val_loss: 20375.5658\n",
      "Epoch 589/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 14967.1915 - val_loss: 20046.1426\n",
      "Epoch 590/1000\n",
      "1137/1137 [==============================] - 0s 254us/step - loss: 15004.9723 - val_loss: 24744.2758\n",
      "Epoch 591/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: 15501.3583 - val_loss: 20107.2587\n",
      "Epoch 592/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 15240.2491 - val_loss: 21696.4717\n",
      "Epoch 593/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: 15217.6419 - val_loss: 22051.6746\n",
      "Epoch 594/1000\n",
      "1137/1137 [==============================] - 0s 267us/step - loss: 15819.5257 - val_loss: 20476.0218\n",
      "Epoch 595/1000\n",
      "1137/1137 [==============================] - 0s 317us/step - loss: 14921.3423 - val_loss: 20807.3774\n",
      "Epoch 596/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 15753.7052 - val_loss: 21635.6858\n",
      "Epoch 597/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 14709.0925 - val_loss: 20154.7540\n",
      "Epoch 598/1000\n",
      "1137/1137 [==============================] - 0s 293us/step - loss: 14669.6333 - val_loss: 20283.7116\n",
      "Epoch 599/1000\n",
      "1137/1137 [==============================] - 0s 269us/step - loss: 14962.8810 - val_loss: 19965.8544\n",
      "Epoch 600/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 15303.7248 - val_loss: 21168.6963\n",
      "Epoch 601/1000\n",
      "1137/1137 [==============================] - 0s 254us/step - loss: 14882.3198 - val_loss: 20536.4094\n",
      "Epoch 602/1000\n",
      "1137/1137 [==============================] - 0s 323us/step - loss: 14950.3020 - val_loss: 23031.0830\n",
      "Epoch 603/1000\n",
      "1137/1137 [==============================] - 0s 256us/step - loss: 14814.2602 - val_loss: 20213.0528\n",
      "Epoch 604/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: 15452.6332 - val_loss: 20832.8516\n",
      "Epoch 605/1000\n",
      "1137/1137 [==============================] - 0s 289us/step - loss: 14546.6556 - val_loss: 19817.8288\n",
      "Epoch 606/1000\n",
      "1137/1137 [==============================] - 0s 282us/step - loss: 14550.3809 - val_loss: 20630.1043\n",
      "Epoch 607/1000\n",
      "1137/1137 [==============================] - 0s 276us/step - loss: 14983.6615 - val_loss: 21161.3253\n",
      "Epoch 608/1000\n",
      "1137/1137 [==============================] - 0s 307us/step - loss: 14720.9085 - val_loss: 20185.3360\n",
      "Epoch 609/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 14837.8135 - val_loss: 19964.3171\n",
      "Epoch 610/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 14640.9600 - val_loss: 20667.9077\n",
      "Epoch 611/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 15510.6959 - val_loss: 19888.3731\n",
      "Epoch 612/1000\n",
      "1137/1137 [==============================] - 0s 286us/step - loss: 14859.1959 - val_loss: 21510.3805\n",
      "Epoch 613/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 14418.7042 - val_loss: 20927.1427\n",
      "Epoch 614/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 14538.3050 - val_loss: 20811.2561\n",
      "Epoch 615/1000\n",
      "1137/1137 [==============================] - 0s 300us/step - loss: 14748.7894 - val_loss: 20167.3777\n",
      "Epoch 616/1000\n",
      "1137/1137 [==============================] - 0s 297us/step - loss: 14640.6158 - val_loss: 19685.7436\n",
      "Epoch 617/1000\n",
      "1137/1137 [==============================] - 0s 289us/step - loss: 14534.8124 - val_loss: 19916.7082\n",
      "Epoch 618/1000\n",
      "1137/1137 [==============================] - 0s 301us/step - loss: 14698.9094 - val_loss: 20621.9820\n",
      "Epoch 619/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: 14422.4127 - val_loss: 20243.7485\n",
      "Epoch 620/1000\n",
      "1137/1137 [==============================] - 0s 299us/step - loss: 14633.1120 - val_loss: 19931.4002\n",
      "Epoch 621/1000\n",
      "1137/1137 [==============================] - 0s 305us/step - loss: 14881.0204 - val_loss: 19823.6542\n",
      "Epoch 622/1000\n",
      "1137/1137 [==============================] - 0s 332us/step - loss: 14596.1333 - val_loss: 19789.5342\n",
      "Epoch 623/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: 14696.2833 - val_loss: 21222.0407\n",
      "Epoch 624/1000\n",
      "1137/1137 [==============================] - 0s 297us/step - loss: 14372.4862 - val_loss: 19960.2656\n",
      "Epoch 625/1000\n",
      "1137/1137 [==============================] - 0s 332us/step - loss: 14685.7155 - val_loss: 19925.6021\n",
      "Epoch 626/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 14354.6688 - val_loss: 21190.4563\n",
      "Epoch 627/1000\n",
      "1137/1137 [==============================] - 0s 318us/step - loss: 15128.4432 - val_loss: 19993.8797\n",
      "Epoch 628/1000\n",
      "1137/1137 [==============================] - 0s 333us/step - loss: 14859.5081 - val_loss: 20270.6709\n",
      "Epoch 629/1000\n",
      "1137/1137 [==============================] - 0s 248us/step - loss: 14693.7141 - val_loss: 19829.6066\n",
      "Epoch 630/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: 15284.3946 - val_loss: 21973.3485\n",
      "Epoch 631/1000\n",
      "1137/1137 [==============================] - 0s 312us/step - loss: 14916.6319 - val_loss: 19991.4650\n",
      "Epoch 632/1000\n",
      "1137/1137 [==============================] - 0s 273us/step - loss: 14994.3990 - val_loss: 22062.8840\n",
      "Epoch 633/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: 14894.4529 - val_loss: 20068.7538\n",
      "Epoch 634/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: 14662.2215 - val_loss: 20158.2157\n",
      "Epoch 635/1000\n",
      "1137/1137 [==============================] - 0s 294us/step - loss: 14902.9676 - val_loss: 20059.9400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 636/1000\n",
      "1137/1137 [==============================] - 0s 260us/step - loss: 14916.9551 - val_loss: 20194.5712\n",
      "Epoch 637/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 14630.7778 - val_loss: 21102.7280\n",
      "Epoch 638/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: 15058.4499 - val_loss: 19611.2412\n",
      "Epoch 639/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: 14491.1517 - val_loss: 20211.1166\n",
      "Epoch 640/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: 14535.1444 - val_loss: 20521.6013\n",
      "Epoch 641/1000\n",
      "1137/1137 [==============================] - 0s 248us/step - loss: 14364.3196 - val_loss: 20982.6905\n",
      "Epoch 642/1000\n",
      "1137/1137 [==============================] - 0s 282us/step - loss: 14377.1600 - val_loss: 20822.3630\n",
      "Epoch 643/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 15082.9673 - val_loss: 20995.6679\n",
      "Epoch 644/1000\n",
      "1137/1137 [==============================] - 0s 260us/step - loss: 14842.4252 - val_loss: 21334.5752\n",
      "Epoch 645/1000\n",
      "1137/1137 [==============================] - 0s 293us/step - loss: 15186.5871 - val_loss: 19971.8006\n",
      "Epoch 646/1000\n",
      "1137/1137 [==============================] - 0s 255us/step - loss: 14689.1418 - val_loss: 21374.5444\n",
      "Epoch 647/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 14236.0519 - val_loss: 20314.8216\n",
      "Epoch 648/1000\n",
      "1137/1137 [==============================] - 0s 255us/step - loss: 14951.6934 - val_loss: 19959.3821\n",
      "Epoch 649/1000\n",
      "1137/1137 [==============================] - 0s 288us/step - loss: 14214.0424 - val_loss: 20162.9288\n",
      "Epoch 650/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 14368.2801 - val_loss: 22217.2245\n",
      "Epoch 651/1000\n",
      "1137/1137 [==============================] - 0s 276us/step - loss: 15342.8028 - val_loss: 20209.6262\n",
      "Epoch 652/1000\n",
      "1137/1137 [==============================] - 0s 267us/step - loss: 14141.8944 - val_loss: 21049.7965\n",
      "Epoch 653/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 15025.5228 - val_loss: 20750.6489\n",
      "Epoch 654/1000\n",
      "1137/1137 [==============================] - 0s 276us/step - loss: 14934.1134 - val_loss: 19828.9021\n",
      "Epoch 655/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 14675.7548 - val_loss: 23428.9256\n",
      "Epoch 656/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 15209.9685 - val_loss: 20859.7644\n",
      "Epoch 657/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: 15112.1362 - val_loss: 20229.1460\n",
      "Epoch 658/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 14730.5758 - val_loss: 20085.8589\n",
      "Epoch 659/1000\n",
      "1137/1137 [==============================] - 0s 263us/step - loss: 15159.9301 - val_loss: 19725.5768\n",
      "Epoch 660/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: 14153.5111 - val_loss: 20111.6986\n",
      "Epoch 661/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 14457.7000 - val_loss: 20279.3974\n",
      "Epoch 662/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 14470.0280 - val_loss: 19536.2908\n",
      "Epoch 663/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 14682.1409 - val_loss: 21529.8922\n",
      "Epoch 664/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 14621.1590 - val_loss: 19915.3290\n",
      "Epoch 665/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 14212.6865 - val_loss: 20439.9721\n",
      "Epoch 666/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 14112.4807 - val_loss: 19747.5945\n",
      "Epoch 667/1000\n",
      "1137/1137 [==============================] - 0s 297us/step - loss: 14070.4803 - val_loss: 20198.6886\n",
      "Epoch 668/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: 14446.6492 - val_loss: 20095.7132\n",
      "Epoch 669/1000\n",
      "1137/1137 [==============================] - 0s 267us/step - loss: 14412.5455 - val_loss: 21086.1713\n",
      "Epoch 670/1000\n",
      "1137/1137 [==============================] - 0s 297us/step - loss: 14718.9362 - val_loss: 19804.2431\n",
      "Epoch 671/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 14122.1605 - val_loss: 20264.1669\n",
      "Epoch 672/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 14863.2613 - val_loss: 19968.2431\n",
      "Epoch 673/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: 14093.4756 - val_loss: 19847.2498\n",
      "Epoch 674/1000\n",
      "1137/1137 [==============================] - 0s 312us/step - loss: 15065.6804 - val_loss: 20043.3713\n",
      "Epoch 675/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 14022.8623 - val_loss: 19941.3364\n",
      "Epoch 676/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 14498.6361 - val_loss: 19938.4123\n",
      "Epoch 677/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 15064.2878 - val_loss: 19578.9732\n",
      "Epoch 678/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: 14624.8517 - val_loss: 20497.3430\n",
      "Epoch 679/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 14978.2170 - val_loss: 19472.8311\n",
      "Epoch 680/1000\n",
      "1137/1137 [==============================] - 0s 267us/step - loss: 14375.8463 - val_loss: 19610.8671\n",
      "Epoch 681/1000\n",
      "1137/1137 [==============================] - 0s 301us/step - loss: 14413.8219 - val_loss: 19571.2377\n",
      "Epoch 682/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: 15565.6017 - val_loss: 20774.9110\n",
      "Epoch 683/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 14265.1147 - val_loss: 20604.4497\n",
      "Epoch 684/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 14778.5103 - val_loss: 19503.6989\n",
      "Epoch 685/1000\n",
      "1137/1137 [==============================] - 0s 254us/step - loss: 14110.5231 - val_loss: 19672.4823\n",
      "Epoch 686/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 14385.8701 - val_loss: 20170.6006\n",
      "Epoch 687/1000\n",
      "1137/1137 [==============================] - 0s 268us/step - loss: 14769.9443 - val_loss: 20278.2604\n",
      "Epoch 688/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 14317.8366 - val_loss: 19602.5514\n",
      "Epoch 689/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: 14907.2992 - val_loss: 21276.2670\n",
      "Epoch 690/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 14575.8338 - val_loss: 20452.3855\n",
      "Epoch 691/1000\n",
      "1137/1137 [==============================] - 0s 294us/step - loss: 14281.8875 - val_loss: 19741.1898\n",
      "Epoch 692/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 14635.6340 - val_loss: 19953.4194\n",
      "Epoch 693/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 14138.3401 - val_loss: 19945.5342\n",
      "Epoch 694/1000\n",
      "1137/1137 [==============================] - 0s 282us/step - loss: 14204.6089 - val_loss: 19693.3959\n",
      "Epoch 695/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: 14600.5372 - val_loss: 19859.8735\n",
      "Epoch 696/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: 14410.6536 - val_loss: 20795.7820\n",
      "Epoch 697/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 14128.0495 - val_loss: 20735.4600\n",
      "Epoch 698/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: 14378.8551 - val_loss: 19390.9644\n",
      "Epoch 699/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 14146.6845 - val_loss: 20574.7318\n",
      "Epoch 700/1000\n",
      "1137/1137 [==============================] - 0s 273us/step - loss: 14397.4834 - val_loss: 20200.6534\n",
      "Epoch 701/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: 14139.9436 - val_loss: 19996.3814\n",
      "Epoch 702/1000\n",
      "1137/1137 [==============================] - 0s 288us/step - loss: 13984.1964 - val_loss: 21046.6708\n",
      "Epoch 703/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 15514.8051 - val_loss: 22936.8955\n",
      "Epoch 704/1000\n",
      "1137/1137 [==============================] - 0s 260us/step - loss: 14546.4277 - val_loss: 19703.3865\n",
      "Epoch 705/1000\n",
      "1137/1137 [==============================] - 0s 287us/step - loss: 14713.7793 - val_loss: 19493.0996\n",
      "Epoch 706/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 252us/step - loss: 14777.8001 - val_loss: 19498.5559\n",
      "Epoch 707/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: 14014.5300 - val_loss: 20715.5409\n",
      "Epoch 708/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: 14624.3874 - val_loss: 21327.1518\n",
      "Epoch 709/1000\n",
      "1137/1137 [==============================] - 0s 310us/step - loss: 14339.0644 - val_loss: 19291.5403\n",
      "Epoch 710/1000\n",
      "1137/1137 [==============================] - 0s 299us/step - loss: 14678.1012 - val_loss: 20216.1962\n",
      "Epoch 711/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: 14311.9123 - val_loss: 22304.7193\n",
      "Epoch 712/1000\n",
      "1137/1137 [==============================] - 0s 319us/step - loss: 14026.2332 - val_loss: 19596.5836\n",
      "Epoch 713/1000\n",
      "1137/1137 [==============================] - 0s 307us/step - loss: 13777.6777 - val_loss: 19988.4212\n",
      "Epoch 714/1000\n",
      "1137/1137 [==============================] - 0s 306us/step - loss: 13939.8335 - val_loss: 19876.3181\n",
      "Epoch 715/1000\n",
      "1137/1137 [==============================] - 0s 335us/step - loss: 14627.6716 - val_loss: 20484.0942\n",
      "Epoch 716/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: 14078.0645 - val_loss: 19974.3294\n",
      "Epoch 717/1000\n",
      "1137/1137 [==============================] - 0s 320us/step - loss: 14200.2771 - val_loss: 19897.3690\n",
      "Epoch 718/1000\n",
      "1137/1137 [==============================] - 0s 309us/step - loss: 14282.3456 - val_loss: 22846.1828\n",
      "Epoch 719/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: 14131.1742 - val_loss: 20011.1490\n",
      "Epoch 720/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: 13996.0438 - val_loss: 19634.6555\n",
      "Epoch 721/1000\n",
      "1137/1137 [==============================] - 0s 330us/step - loss: 14427.8127 - val_loss: 20182.1544\n",
      "Epoch 722/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 14086.0357 - val_loss: 21297.2957\n",
      "Epoch 723/1000\n",
      "1137/1137 [==============================] - 0s 253us/step - loss: 13806.8571 - val_loss: 19395.2727\n",
      "Epoch 724/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 14128.4958 - val_loss: 19711.9123\n",
      "Epoch 725/1000\n",
      "1137/1137 [==============================] - 0s 299us/step - loss: 13611.9214 - val_loss: 19607.6496\n",
      "Epoch 726/1000\n",
      "1137/1137 [==============================] - 0s 276us/step - loss: 14248.5613 - val_loss: 21748.5693\n",
      "Epoch 727/1000\n",
      "1137/1137 [==============================] - 0s 254us/step - loss: 13798.1935 - val_loss: 19244.9981\n",
      "Epoch 728/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: 14013.1615 - val_loss: 20339.9792\n",
      "Epoch 729/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: 13728.7323 - val_loss: 19362.0381\n",
      "Epoch 730/1000\n",
      "1137/1137 [==============================] - 0s 248us/step - loss: 14263.4043 - val_loss: 20197.9098\n",
      "Epoch 731/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: 13923.0022 - val_loss: 21757.0515\n",
      "Epoch 732/1000\n",
      "1137/1137 [==============================] - 0s 287us/step - loss: 14302.3577 - val_loss: 19623.8488\n",
      "Epoch 733/1000\n",
      "1137/1137 [==============================] - 0s 253us/step - loss: 14037.3028 - val_loss: 19623.0173\n",
      "Epoch 734/1000\n",
      "1137/1137 [==============================] - 0s 263us/step - loss: 13682.8811 - val_loss: 20287.1992\n",
      "Epoch 735/1000\n",
      "1137/1137 [==============================] - 0s 297us/step - loss: 14037.3418 - val_loss: 19456.3507\n",
      "Epoch 736/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 14208.2796 - val_loss: 19402.9639\n",
      "Epoch 737/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: 13835.7910 - val_loss: 19501.6666\n",
      "Epoch 738/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 13798.3599 - val_loss: 20423.8399\n",
      "Epoch 739/1000\n",
      "1137/1137 [==============================] - 0s 302us/step - loss: 14047.9766 - val_loss: 20078.7414\n",
      "Epoch 740/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 14077.1824 - val_loss: 19633.3437\n",
      "Epoch 741/1000\n",
      "1137/1137 [==============================] - 0s 246us/step - loss: 14013.5651 - val_loss: 20209.8083\n",
      "Epoch 742/1000\n",
      "1137/1137 [==============================] - 0s 273us/step - loss: 14256.0912 - val_loss: 19980.5633\n",
      "Epoch 743/1000\n",
      "1137/1137 [==============================] - 0s 274us/step - loss: 14876.4611 - val_loss: 21047.2802\n",
      "Epoch 744/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: 14100.2688 - val_loss: 19654.3576\n",
      "Epoch 745/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: 13834.8039 - val_loss: 20490.1573\n",
      "Epoch 746/1000\n",
      "1137/1137 [==============================] - 0s 290us/step - loss: 13785.8204 - val_loss: 20368.4520\n",
      "Epoch 747/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: 14242.6254 - val_loss: 19500.5444\n",
      "Epoch 748/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: 14572.0887 - val_loss: 19945.0145\n",
      "Epoch 749/1000\n",
      "1137/1137 [==============================] - 0s 267us/step - loss: 13636.2649 - val_loss: 19359.0518\n",
      "Epoch 750/1000\n",
      "1137/1137 [==============================] - 0s 281us/step - loss: 14589.5739 - val_loss: 19817.9921\n",
      "Epoch 751/1000\n",
      "1137/1137 [==============================] - 0s 273us/step - loss: 13860.0678 - val_loss: 20692.0971\n",
      "Epoch 752/1000\n",
      "1137/1137 [==============================] - 0s 274us/step - loss: 14503.1988 - val_loss: 19476.4931\n",
      "Epoch 753/1000\n",
      "1137/1137 [==============================] - 0s 288us/step - loss: 14115.1179 - val_loss: 22733.9370\n",
      "Epoch 754/1000\n",
      "1137/1137 [==============================] - 0s 269us/step - loss: 14165.7172 - val_loss: 19745.9804\n",
      "Epoch 755/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: nan - val_loss: nan\n",
      "Epoch 756/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: nan - val_loss: nan\n",
      "Epoch 757/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: nan - val_loss: nan\n",
      "Epoch 758/1000\n",
      "1137/1137 [==============================] - 0s 274us/step - loss: nan - val_loss: nan\n",
      "Epoch 759/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: nan - val_loss: nan\n",
      "Epoch 760/1000\n",
      "1137/1137 [==============================] - 0s 296us/step - loss: nan - val_loss: nan\n",
      "Epoch 761/1000\n",
      "1137/1137 [==============================] - 0s 273us/step - loss: nan - val_loss: nan\n",
      "Epoch 762/1000\n",
      "1137/1137 [==============================] - 0s 253us/step - loss: nan - val_loss: nan\n",
      "Epoch 763/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: nan - val_loss: nan\n",
      "Epoch 764/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 765/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: nan - val_loss: nan\n",
      "Epoch 766/1000\n",
      "1137/1137 [==============================] - 0s 280us/step - loss: nan - val_loss: nan\n",
      "Epoch 767/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: nan - val_loss: nan\n",
      "Epoch 768/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: nan - val_loss: nan\n",
      "Epoch 769/1000\n",
      "1137/1137 [==============================] - 0s 262us/step - loss: nan - val_loss: nan\n",
      "Epoch 770/1000\n",
      "1137/1137 [==============================] - 0s 299us/step - loss: nan - val_loss: nan\n",
      "Epoch 771/1000\n",
      "1137/1137 [==============================] - 0s 253us/step - loss: nan - val_loss: nan\n",
      "Epoch 772/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: nan - val_loss: nan\n",
      "Epoch 773/1000\n",
      "1137/1137 [==============================] - 0s 255us/step - loss: nan - val_loss: nan\n",
      "Epoch 774/1000\n",
      "1137/1137 [==============================] - 0s 319us/step - loss: nan - val_loss: nan\n",
      "Epoch 775/1000\n",
      "1137/1137 [==============================] - 0s 269us/step - loss: nan - val_loss: nan\n",
      "Epoch 776/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: nan - val_loss: nan\n",
      "Epoch 777/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: nan - val_loss: nan\n",
      "Epoch 778/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: nan - val_loss: nan\n",
      "Epoch 779/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 279us/step - loss: nan - val_loss: nan\n",
      "Epoch 780/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: nan - val_loss: nan\n",
      "Epoch 781/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: nan - val_loss: nan\n",
      "Epoch 782/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 783/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: nan - val_loss: nan\n",
      "Epoch 784/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: nan - val_loss: nan\n",
      "Epoch 785/1000\n",
      "1137/1137 [==============================] - 0s 254us/step - loss: nan - val_loss: nan\n",
      "Epoch 786/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: nan - val_loss: nan\n",
      "Epoch 787/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: nan - val_loss: nan\n",
      "Epoch 788/1000\n",
      "1137/1137 [==============================] - 0s 289us/step - loss: nan - val_loss: nan\n",
      "Epoch 789/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 790/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: nan - val_loss: nan\n",
      "Epoch 791/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: nan - val_loss: nan\n",
      "Epoch 792/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: nan - val_loss: nan\n",
      "Epoch 793/1000\n",
      "1137/1137 [==============================] - 0s 250us/step - loss: nan - val_loss: nan\n",
      "Epoch 794/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: nan - val_loss: nan\n",
      "Epoch 795/1000\n",
      "1137/1137 [==============================] - 0s 274us/step - loss: nan - val_loss: nan\n",
      "Epoch 796/1000\n",
      "1137/1137 [==============================] - 0s 254us/step - loss: nan - val_loss: nan\n",
      "Epoch 797/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 798/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: nan - val_loss: nan\n",
      "Epoch 799/1000\n",
      "1137/1137 [==============================] - 0s 299us/step - loss: nan - val_loss: nan\n",
      "Epoch 800/1000\n",
      "1137/1137 [==============================] - 0s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 801/1000\n",
      "1137/1137 [==============================] - 0s 310us/step - loss: nan - val_loss: nan\n",
      "Epoch 802/1000\n",
      "1137/1137 [==============================] - 0s 365us/step - loss: nan - val_loss: nan\n",
      "Epoch 803/1000\n",
      "1137/1137 [==============================] - 0s 342us/step - loss: nan - val_loss: nan\n",
      "Epoch 804/1000\n",
      "1137/1137 [==============================] - 0s 363us/step - loss: nan - val_loss: nan\n",
      "Epoch 805/1000\n",
      "1137/1137 [==============================] - 0s 397us/step - loss: nan - val_loss: nan\n",
      "Epoch 806/1000\n",
      "1137/1137 [==============================] - 0s 347us/step - loss: nan - val_loss: nan\n",
      "Epoch 807/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: nan - val_loss: nan\n",
      "Epoch 808/1000\n",
      "1137/1137 [==============================] - 0s 340us/step - loss: nan - val_loss: nan\n",
      "Epoch 809/1000\n",
      "1137/1137 [==============================] - 0s 396us/step - loss: nan - val_loss: nan\n",
      "Epoch 810/1000\n",
      "1137/1137 [==============================] - 0s 401us/step - loss: nan - val_loss: nan\n",
      "Epoch 811/1000\n",
      "1137/1137 [==============================] - 0s 336us/step - loss: nan - val_loss: nan\n",
      "Epoch 812/1000\n",
      "1137/1137 [==============================] - 0s 347us/step - loss: nan - val_loss: nan\n",
      "Epoch 813/1000\n",
      "1137/1137 [==============================] - 0s 388us/step - loss: nan - val_loss: nan\n",
      "Epoch 814/1000\n",
      "1137/1137 [==============================] - 0s 338us/step - loss: nan - val_loss: nan\n",
      "Epoch 815/1000\n",
      "1137/1137 [==============================] - 0s 365us/step - loss: nan - val_loss: nan\n",
      "Epoch 816/1000\n",
      "1137/1137 [==============================] - 0s 361us/step - loss: nan - val_loss: nan\n",
      "Epoch 817/1000\n",
      "1137/1137 [==============================] - 0s 332us/step - loss: nan - val_loss: nan\n",
      "Epoch 818/1000\n",
      "1137/1137 [==============================] - 0s 328us/step - loss: nan - val_loss: nan\n",
      "Epoch 819/1000\n",
      "1137/1137 [==============================] - 0s 280us/step - loss: nan - val_loss: nan\n",
      "Epoch 820/1000\n",
      "1137/1137 [==============================] - 0s 273us/step - loss: nan - val_loss: nan\n",
      "Epoch 821/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: nan - val_loss: nan\n",
      "Epoch 822/1000\n",
      "1137/1137 [==============================] - 0s 297us/step - loss: nan - val_loss: nan\n",
      "Epoch 823/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: nan - val_loss: nan\n",
      "Epoch 824/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 825/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: nan - val_loss: nan\n",
      "Epoch 826/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 827/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 828/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: nan - val_loss: nan\n",
      "Epoch 829/1000\n",
      "1137/1137 [==============================] - 0s 299us/step - loss: nan - val_loss: nan\n",
      "Epoch 830/1000\n",
      "1137/1137 [==============================] - 0s 269us/step - loss: nan - val_loss: nan\n",
      "Epoch 831/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: nan - val_loss: nan\n",
      "Epoch 832/1000\n",
      "1137/1137 [==============================] - 0s 280us/step - loss: nan - val_loss: nan\n",
      "Epoch 833/1000\n",
      "1137/1137 [==============================] - 0s 338us/step - loss: nan - val_loss: nan\n",
      "Epoch 834/1000\n",
      "1137/1137 [==============================] - 0s 249us/step - loss: nan - val_loss: nan\n",
      "Epoch 835/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: nan - val_loss: nan\n",
      "Epoch 836/1000\n",
      "1137/1137 [==============================] - 0s 296us/step - loss: nan - val_loss: nan\n",
      "Epoch 837/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 838/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: nan - val_loss: nan\n",
      "Epoch 839/1000\n",
      "1137/1137 [==============================] - 0s 289us/step - loss: nan - val_loss: nan\n",
      "Epoch 840/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: nan - val_loss: nan\n",
      "Epoch 841/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: nan - val_loss: nan\n",
      "Epoch 842/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: nan - val_loss: nan\n",
      "Epoch 843/1000\n",
      "1137/1137 [==============================] - 0s 289us/step - loss: nan - val_loss: nan\n",
      "Epoch 844/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: nan - val_loss: nan\n",
      "Epoch 845/1000\n",
      "1137/1137 [==============================] - 0s 254us/step - loss: nan - val_loss: nan\n",
      "Epoch 846/1000\n",
      "1137/1137 [==============================] - 0s 298us/step - loss: nan - val_loss: nan\n",
      "Epoch 847/1000\n",
      "1137/1137 [==============================] - 0s 255us/step - loss: nan - val_loss: nan\n",
      "Epoch 848/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: nan - val_loss: nan\n",
      "Epoch 849/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: nan - val_loss: nan\n",
      "Epoch 850/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: nan - val_loss: nan\n",
      "Epoch 851/1000\n",
      "1137/1137 [==============================] - 0s 268us/step - loss: nan - val_loss: nan\n",
      "Epoch 852/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: nan - val_loss: nan\n",
      "Epoch 853/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: nan - val_loss: nan\n",
      "Epoch 854/1000\n",
      "1137/1137 [==============================] - 0s 245us/step - loss: nan - val_loss: nan\n",
      "Epoch 855/1000\n",
      "1137/1137 [==============================] - 0s 274us/step - loss: nan - val_loss: nan\n",
      "Epoch 856/1000\n",
      "1137/1137 [==============================] - 0s 266us/step - loss: nan - val_loss: nan\n",
      "Epoch 857/1000\n",
      "1137/1137 [==============================] - 0s 311us/step - loss: nan - val_loss: nan\n",
      "Epoch 858/1000\n",
      "1137/1137 [==============================] - 0s 269us/step - loss: nan - val_loss: nan\n",
      "Epoch 859/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 265us/step - loss: nan - val_loss: nan\n",
      "Epoch 860/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: nan - val_loss: nan\n",
      "Epoch 861/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: nan - val_loss: nan\n",
      "Epoch 862/1000\n",
      "1137/1137 [==============================] - 0s 272us/step - loss: nan - val_loss: nan\n",
      "Epoch 863/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 864/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: nan - val_loss: nan\n",
      "Epoch 865/1000\n",
      "1137/1137 [==============================] - 0s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 866/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: nan - val_loss: nan\n",
      "Epoch 867/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: nan - val_loss: nan\n",
      "Epoch 868/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: nan - val_loss: nan\n",
      "Epoch 869/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 870/1000\n",
      "1137/1137 [==============================] - 0s 263us/step - loss: nan - val_loss: nan\n",
      "Epoch 871/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: nan - val_loss: nan\n",
      "Epoch 872/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 873/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: nan - val_loss: nan\n",
      "Epoch 874/1000\n",
      "1137/1137 [==============================] - 0s 263us/step - loss: nan - val_loss: nan\n",
      "Epoch 875/1000\n",
      "1137/1137 [==============================] - 0s 286us/step - loss: nan - val_loss: nan\n",
      "Epoch 876/1000\n",
      "1137/1137 [==============================] - 0s 253us/step - loss: nan - val_loss: nan\n",
      "Epoch 877/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: nan - val_loss: nan\n",
      "Epoch 878/1000\n",
      "1137/1137 [==============================] - 0s 288us/step - loss: nan - val_loss: nan\n",
      "Epoch 879/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 880/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: nan - val_loss: nan\n",
      "Epoch 881/1000\n",
      "1137/1137 [==============================] - 0s 250us/step - loss: nan - val_loss: nan\n",
      "Epoch 882/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: nan - val_loss: nan\n",
      "Epoch 883/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: nan - val_loss: nan\n",
      "Epoch 884/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 885/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: nan - val_loss: nan\n",
      "Epoch 886/1000\n",
      "1137/1137 [==============================] - 0s 260us/step - loss: nan - val_loss: nan\n",
      "Epoch 887/1000\n",
      "1137/1137 [==============================] - 0s 267us/step - loss: nan - val_loss: nan\n",
      "Epoch 888/1000\n",
      "1137/1137 [==============================] - 0s 267us/step - loss: nan - val_loss: nan\n",
      "Epoch 889/1000\n",
      "1137/1137 [==============================] - 0s 325us/step - loss: nan - val_loss: nan\n",
      "Epoch 890/1000\n",
      "1137/1137 [==============================] - 0s 248us/step - loss: nan - val_loss: nan\n",
      "Epoch 891/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: nan - val_loss: nan\n",
      "Epoch 892/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: nan - val_loss: nan\n",
      "Epoch 893/1000\n",
      "1137/1137 [==============================] - 0s 254us/step - loss: nan - val_loss: nan\n",
      "Epoch 894/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: nan - val_loss: nan\n",
      "Epoch 895/1000\n",
      "1137/1137 [==============================] - 0s 299us/step - loss: nan - val_loss: nan\n",
      "Epoch 896/1000\n",
      "1137/1137 [==============================] - 0s 352us/step - loss: nan - val_loss: nan\n",
      "Epoch 897/1000\n",
      "1137/1137 [==============================] - 0s 305us/step - loss: nan - val_loss: nan\n",
      "Epoch 898/1000\n",
      "1137/1137 [==============================] - 0s 303us/step - loss: nan - val_loss: nan\n",
      "Epoch 899/1000\n",
      "1137/1137 [==============================] - 0s 353us/step - loss: nan - val_loss: nan\n",
      "Epoch 900/1000\n",
      "1137/1137 [==============================] - 0s 300us/step - loss: nan - val_loss: nan\n",
      "Epoch 901/1000\n",
      "1137/1137 [==============================] - 0s 326us/step - loss: nan - val_loss: nan\n",
      "Epoch 902/1000\n",
      "1137/1137 [==============================] - 0s 336us/step - loss: nan - val_loss: nan\n",
      "Epoch 903/1000\n",
      "1137/1137 [==============================] - 0s 306us/step - loss: nan - val_loss: nan\n",
      "Epoch 904/1000\n",
      "1137/1137 [==============================] - 0s 299us/step - loss: nan - val_loss: nan\n",
      "Epoch 905/1000\n",
      "1137/1137 [==============================] - 0s 371us/step - loss: nan - val_loss: nan\n",
      "Epoch 906/1000\n",
      "1137/1137 [==============================] - 0s 343us/step - loss: nan - val_loss: nan\n",
      "Epoch 907/1000\n",
      "1137/1137 [==============================] - 0s 305us/step - loss: nan - val_loss: nan\n",
      "Epoch 908/1000\n",
      "1137/1137 [==============================] - 0s 305us/step - loss: nan - val_loss: nan\n",
      "Epoch 909/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: nan - val_loss: nan\n",
      "Epoch 910/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 911/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: nan - val_loss: nan\n",
      "Epoch 912/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: nan - val_loss: nan\n",
      "Epoch 913/1000\n",
      "1137/1137 [==============================] - 0s 263us/step - loss: nan - val_loss: nan\n",
      "Epoch 914/1000\n",
      "1137/1137 [==============================] - 0s 275us/step - loss: nan - val_loss: nan\n",
      "Epoch 915/1000\n",
      "1137/1137 [==============================] - 0s 280us/step - loss: nan - val_loss: nan\n",
      "Epoch 916/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 917/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: nan - val_loss: nan\n",
      "Epoch 918/1000\n",
      "1137/1137 [==============================] - 0s 288us/step - loss: nan - val_loss: nan\n",
      "Epoch 919/1000\n",
      "1137/1137 [==============================] - 0s 250us/step - loss: nan - val_loss: nan\n",
      "Epoch 920/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: nan - val_loss: nan\n",
      "Epoch 921/1000\n",
      "1137/1137 [==============================] - 0s 285us/step - loss: nan - val_loss: nan\n",
      "Epoch 922/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: nan - val_loss: nan\n",
      "Epoch 923/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: nan - val_loss: nan\n",
      "Epoch 924/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: nan - val_loss: nan\n",
      "Epoch 925/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: nan - val_loss: nan\n",
      "Epoch 926/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: nan - val_loss: nan\n",
      "Epoch 927/1000\n",
      "1137/1137 [==============================] - 0s 343us/step - loss: nan - val_loss: nan\n",
      "Epoch 928/1000\n",
      "1137/1137 [==============================] - 0s 267us/step - loss: nan - val_loss: nan\n",
      "Epoch 929/1000\n",
      "1137/1137 [==============================] - 0s 287us/step - loss: nan - val_loss: nan\n",
      "Epoch 930/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 931/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: nan - val_loss: nan\n",
      "Epoch 932/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: nan - val_loss: nan\n",
      "Epoch 933/1000\n",
      "1137/1137 [==============================] - 0s 261us/step - loss: nan - val_loss: nan\n",
      "Epoch 934/1000\n",
      "1137/1137 [==============================] - 0s 278us/step - loss: nan - val_loss: nan\n",
      "Epoch 935/1000\n",
      "1137/1137 [==============================] - 0s 256us/step - loss: nan - val_loss: nan\n",
      "Epoch 936/1000\n",
      "1137/1137 [==============================] - 0s 297us/step - loss: nan - val_loss: nan\n",
      "Epoch 937/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: nan - val_loss: nan\n",
      "Epoch 938/1000\n",
      "1137/1137 [==============================] - 0s 265us/step - loss: nan - val_loss: nan\n",
      "Epoch 939/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 288us/step - loss: nan - val_loss: nan\n",
      "Epoch 940/1000\n",
      "1137/1137 [==============================] - 0s 253us/step - loss: nan - val_loss: nan\n",
      "Epoch 941/1000\n",
      "1137/1137 [==============================] - 0s 280us/step - loss: nan - val_loss: nan\n",
      "Epoch 942/1000\n",
      "1137/1137 [==============================] - 0s 253us/step - loss: nan - val_loss: nan\n",
      "Epoch 943/1000\n",
      "1137/1137 [==============================] - 0s 292us/step - loss: nan - val_loss: nan\n",
      "Epoch 944/1000\n",
      "1137/1137 [==============================] - 0s 249us/step - loss: nan - val_loss: nan\n",
      "Epoch 945/1000\n",
      "1137/1137 [==============================] - 0s 266us/step - loss: nan - val_loss: nan\n",
      "Epoch 946/1000\n",
      "1137/1137 [==============================] - 0s 303us/step - loss: nan - val_loss: nan\n",
      "Epoch 947/1000\n",
      "1137/1137 [==============================] - 0s 259us/step - loss: nan - val_loss: nan\n",
      "Epoch 948/1000\n",
      "1137/1137 [==============================] - 0s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 949/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: nan - val_loss: nan\n",
      "Epoch 950/1000\n",
      "1137/1137 [==============================] - 0s 274us/step - loss: nan - val_loss: nan\n",
      "Epoch 951/1000\n",
      "1137/1137 [==============================] - 0s 252us/step - loss: nan - val_loss: nan\n",
      "Epoch 952/1000\n",
      "1137/1137 [==============================] - 0s 290us/step - loss: nan - val_loss: nan\n",
      "Epoch 953/1000\n",
      "1137/1137 [==============================] - 0s 303us/step - loss: nan - val_loss: nan\n",
      "Epoch 954/1000\n",
      "1137/1137 [==============================] - 0s 328us/step - loss: nan - val_loss: nan\n",
      "Epoch 955/1000\n",
      "1137/1137 [==============================] - 0s 284us/step - loss: nan - val_loss: nan\n",
      "Epoch 956/1000\n",
      "1137/1137 [==============================] - 0s 273us/step - loss: nan - val_loss: nan\n",
      "Epoch 957/1000\n",
      "1137/1137 [==============================] - 0s 291us/step - loss: nan - val_loss: nan\n",
      "Epoch 958/1000\n",
      "1137/1137 [==============================] - 0s 271us/step - loss: nan - val_loss: nan\n",
      "Epoch 959/1000\n",
      "1137/1137 [==============================] - 0s 273us/step - loss: nan - val_loss: nan\n",
      "Epoch 960/1000\n",
      "1137/1137 [==============================] - 0s 296us/step - loss: nan - val_loss: nan\n",
      "Epoch 961/1000\n",
      "1137/1137 [==============================] - 0s 262us/step - loss: nan - val_loss: nan\n",
      "Epoch 962/1000\n",
      "1137/1137 [==============================] - 0s 266us/step - loss: nan - val_loss: nan\n",
      "Epoch 963/1000\n",
      "1137/1137 [==============================] - 0s 254us/step - loss: nan - val_loss: nan\n",
      "Epoch 964/1000\n",
      "1137/1137 [==============================] - 0s 305us/step - loss: nan - val_loss: nan\n",
      "Epoch 965/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: nan - val_loss: nan\n",
      "Epoch 966/1000\n",
      "1137/1137 [==============================] - 0s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 967/1000\n",
      "1137/1137 [==============================] - 0s 303us/step - loss: nan - val_loss: nan\n",
      "Epoch 968/1000\n",
      "1137/1137 [==============================] - 0s 277us/step - loss: nan - val_loss: nan\n",
      "Epoch 969/1000\n",
      "1137/1137 [==============================] - 0s 279us/step - loss: nan - val_loss: nan\n",
      "Epoch 970/1000\n",
      "1137/1137 [==============================] - 0s 327us/step - loss: nan - val_loss: nan\n",
      "Epoch 971/1000\n",
      "1137/1137 [==============================] - 0s 350us/step - loss: nan - val_loss: nan\n",
      "Epoch 972/1000\n",
      "1137/1137 [==============================] - 0s 238us/step - loss: nan - val_loss: nan\n",
      "Epoch 973/1000\n",
      "1137/1137 [==============================] - 0s 260us/step - loss: nan - val_loss: nan\n",
      "Epoch 974/1000\n",
      "1137/1137 [==============================] - 0s 288us/step - loss: nan - val_loss: nan\n",
      "Epoch 975/1000\n",
      "1137/1137 [==============================] - 0s 232us/step - loss: nan - val_loss: nan\n",
      "Epoch 976/1000\n",
      "1137/1137 [==============================] - 0s 251us/step - loss: nan - val_loss: nan\n",
      "Epoch 977/1000\n",
      "1137/1137 [==============================] - 0s 249us/step - loss: nan - val_loss: nan\n",
      "Epoch 978/1000\n",
      "1137/1137 [==============================] - 0s 283us/step - loss: nan - val_loss: nan\n",
      "Epoch 979/1000\n",
      "1137/1137 [==============================] - 0s 233us/step - loss: nan - val_loss: nan\n",
      "Epoch 980/1000\n",
      "1137/1137 [==============================] - 0s 233us/step - loss: nan - val_loss: nan\n",
      "Epoch 981/1000\n",
      "1137/1137 [==============================] - 0s 304us/step - loss: nan - val_loss: nan\n",
      "Epoch 982/1000\n",
      "1137/1137 [==============================] - 0s 270us/step - loss: nan - val_loss: nan\n",
      "Epoch 983/1000\n",
      "1137/1137 [==============================] - 0s 264us/step - loss: nan - val_loss: nan\n",
      "Epoch 984/1000\n",
      "1137/1137 [==============================] - 0s 293us/step - loss: nan - val_loss: nan\n",
      "Epoch 985/1000\n",
      "1137/1137 [==============================] - 0s 328us/step - loss: nan - val_loss: nan\n",
      "Epoch 986/1000\n",
      "1137/1137 [==============================] - 0s 289us/step - loss: nan - val_loss: nan\n",
      "Epoch 987/1000\n",
      "1137/1137 [==============================] - 0s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 988/1000\n",
      "1137/1137 [==============================] - 0s 368us/step - loss: nan - val_loss: nan\n",
      "Epoch 989/1000\n",
      "1137/1137 [==============================] - 0s 310us/step - loss: nan - val_loss: nan\n",
      "Epoch 990/1000\n",
      "1137/1137 [==============================] - 0s 339us/step - loss: nan - val_loss: nan\n",
      "Epoch 991/1000\n",
      "1137/1137 [==============================] - 0s 359us/step - loss: nan - val_loss: nan\n",
      "Epoch 992/1000\n",
      "1137/1137 [==============================] - 0s 343us/step - loss: nan - val_loss: nan\n",
      "Epoch 993/1000\n",
      "1137/1137 [==============================] - 0s 342us/step - loss: nan - val_loss: nan\n",
      "Epoch 994/1000\n",
      "1137/1137 [==============================] - 0s 339us/step - loss: nan - val_loss: nan\n",
      "Epoch 995/1000\n",
      "1137/1137 [==============================] - 0s 314us/step - loss: nan - val_loss: nan\n",
      "Epoch 996/1000\n",
      "1137/1137 [==============================] - 0s 377us/step - loss: nan - val_loss: nan\n",
      "Epoch 997/1000\n",
      "1137/1137 [==============================] - 0s 339us/step - loss: nan - val_loss: nan\n",
      "Epoch 998/1000\n",
      "1137/1137 [==============================] - 0s 394us/step - loss: nan - val_loss: nan\n",
      "Epoch 999/1000\n",
      "1137/1137 [==============================] - 0s 384us/step - loss: nan - val_loss: nan\n",
      "Epoch 1000/1000\n",
      "1137/1137 [==============================] - 0s 301us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e77e05b1c8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Artificial Neural Networks Implementation\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Initialising the ANN\n",
    "regressor=Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "regressor.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "regressor.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "#Adding the third hidden layer\n",
    "regressor.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "\n",
    "regressor.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "regressor.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Test\n",
    "ann_pred=regressor.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0    NaN\n",
       "1    NaN\n",
       "2    NaN\n",
       "3    NaN\n",
       "4    NaN\n",
       "...   ..\n",
       "1454 NaN\n",
       "1455 NaN\n",
       "1456 NaN\n",
       "1457 NaN\n",
       "1458 NaN\n",
       "\n",
       "[1459 rows x 1 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred=pd.DataFrame(ann_pred)\n",
    "#sub_df=pd.read_csv('sample_submission (1).csv')\n",
    "#datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "#datasets.columns=['Id','SalePrice']\n",
    "#datasets.to_csv('MyAnswer.csv',index=False)\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
